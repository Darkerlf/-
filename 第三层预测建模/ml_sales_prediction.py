#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
================================================================================
äºšé©¬é€Šå¨åˆ€å“ç±»é”€é‡é¢„æµ‹ä¸çˆ†æ¬¾è¯†åˆ« - æœºå™¨å­¦ä¹ å»ºæ¨¡
================================================================================
é¡¹ç›®ï¼šæ•°æ™ºé©±åŠ¨ä¸‹çš„"ä¸­å›½å¥½åˆ€" - ä¸‰åˆ›èµ›å‚èµ›æ–¹æ¡ˆ
åŠŸèƒ½ï¼š
    1. XGBoost/LightGBM é”€é‡é¢„æµ‹æ¨¡å‹
    2. SHAP ç‰¹å¾é‡è¦æ€§åˆ†æ
    3. RandomForest çˆ†æ¬¾åˆ†ç±»é¢„æµ‹
    4. äº¤å‰éªŒè¯æ¨¡å‹é²æ£’æ€§è¯„ä¼°
    5. å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆï¼ˆç”¨äºæ¯”èµ›å±•ç¤ºï¼‰

ä½œè€…ï¼šå‚èµ›å›¢é˜Ÿ
æ—¥æœŸï¼š2026å¹´1æœˆ
================================================================================
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
import pickle
import json
from datetime import datetime

# Sklearn
from sklearn.model_selection import train_test_split, cross_val_score, KFold, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import (
    mean_squared_error, mean_absolute_error, r2_score,
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, roc_curve, confusion_matrix, classification_report
)

# å°è¯•å¯¼å…¥é«˜çº§åº“ï¼ˆæœ¬åœ°è¿è¡Œæ—¶ä½¿ç”¨ï¼‰
try:
    import xgboost as xgb
    HAS_XGB = True
except ImportError:
    HAS_XGB = False
    print("âš ï¸ XGBoostæœªå®‰è£…ï¼Œå°†ä½¿ç”¨GradientBoostingRegressoræ›¿ä»£")

try:
    import lightgbm as lgb
    HAS_LGB = True
except ImportError:
    HAS_LGB = False
    print("âš ï¸ LightGBMæœªå®‰è£…ï¼Œå°†ä½¿ç”¨GradientBoostingRegressoræ›¿ä»£")

try:
    import shap
    HAS_SHAP = True
except ImportError:
    HAS_SHAP = False
    print("âš ï¸ SHAPæœªå®‰è£…ï¼Œå°†ä½¿ç”¨sklearnå†…ç½®feature_importances_")

warnings.filterwarnings('ignore')

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False
plt.rcParams['figure.dpi'] = 150
plt.rcParams['savefig.dpi'] = 300
plt.rcParams['figure.figsize'] = (12, 8)

# è®¾ç½®seaborné£æ ¼
sns.set_style("whitegrid")
sns.set_palette("husl")


class AmazonKnifeSalesPredictor:
    """
    äºšé©¬é€Šå¨åˆ€é”€é‡é¢„æµ‹ä¸çˆ†æ¬¾è¯†åˆ«æ¨¡å‹
    """
    
    def __init__(self, data_dir: str, output_dir: str):
        """
        åˆå§‹åŒ–
        
        Args:
            data_dir: æ•°æ®æ–‡ä»¶ç›®å½•
            output_dir: è¾“å‡ºç›®å½•ï¼ˆæ¨¡å‹ã€å›¾ç‰‡ã€æŠ¥å‘Šï¼‰
        """
        self.data_dir = Path(data_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        (self.output_dir / 'models').mkdir(exist_ok=True)
        (self.output_dir / 'figures').mkdir(exist_ok=True)
        (self.output_dir / 'reports').mkdir(exist_ok=True)
        
        # æ•°æ®å®¹å™¨
        self.products = None
        self.reviews = None
        self.agg_product = None
        self.bert_sentiment = None
        self.absa_detailed = None
        
        # å»ºæ¨¡æ•°æ®
        self.df_model = None
        self.X = None
        self.y_regression = None
        self.y_classification = None
        self.feature_names = None
        
        # æ¨¡å‹å®¹å™¨
        self.models = {}
        self.results = {}
        
        print("=" * 60)
        print("ğŸ”ª äºšé©¬é€Šå¨åˆ€é”€é‡é¢„æµ‹ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"ğŸ“ æ•°æ®ç›®å½•: {self.data_dir}")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 60)
    
    def load_data(self):
        """åŠ è½½æ‰€æœ‰æ•°æ®æ–‡ä»¶"""
        print("\nğŸ“¥ æ­£åœ¨åŠ è½½æ•°æ®...")
        
        # åŠ è½½å•†å“æ•°æ®
        self.products = pd.read_csv(self.data_dir / 'products_clean.csv')
        print(f"  âœ“ products_clean.csv: {len(self.products)} æ¡å•†å“")
        
        # åŠ è½½è¯„è®ºæ•°æ®
        self.reviews = pd.read_csv(self.data_dir / 'reviews_cleaned.csv')
        print(f"  âœ“ reviews_cleaned.csv: {len(self.reviews)} æ¡è¯„è®º")
        
        # åŠ è½½èšåˆæ•°æ®
        self.agg_product = pd.read_csv(self.data_dir / 'agg_product.csv')
        print(f"  âœ“ agg_product.csv: {len(self.agg_product)} æ¡èšåˆæ•°æ®")
        
        # åŠ è½½BERTæƒ…æ„Ÿåˆ†æç»“æœ
        self.bert_sentiment = pd.read_csv(self.data_dir / 'bert_sentiment_results.csv')
        print(f"  âœ“ bert_sentiment_results.csv: {len(self.bert_sentiment)} æ¡æƒ…æ„Ÿåˆ†æ")
        
        # åŠ è½½ABSAæ–¹é¢çº§æƒ…æ„Ÿåˆ†æ
        self.absa_detailed = pd.read_csv(self.data_dir / 'absa_detailed.csv')
        print(f"  âœ“ absa_detailed.csv: {len(self.absa_detailed)} æ¡æ–¹é¢æƒ…æ„Ÿ")
        
        print("âœ… æ•°æ®åŠ è½½å®Œæˆ!")
        return self
    
    def _aggregate_bert_sentiment(self) -> pd.DataFrame:
        """èšåˆBERTæƒ…æ„Ÿåˆ†æåˆ°å•†å“çº§"""
        # åˆå¹¶review_idåˆ°asin
        bert_with_asin = self.bert_sentiment.merge(
            self.reviews[['review_id', 'asin']], 
            on='review_id', 
            how='left'
        )
        
        # æŒ‰å•†å“èšåˆ
        bert_agg = bert_with_asin.groupby('asin').agg({
            'bert_score': ['mean', 'std'],
            'bert_label': lambda x: (x == 'POSITIVE').mean()
        }).reset_index()
        
        bert_agg.columns = ['asin', 'avg_bert_score', 'std_bert_score', 'positive_ratio']
        bert_agg['std_bert_score'] = bert_agg['std_bert_score'].fillna(0)
        
        return bert_agg
    
    def _aggregate_absa_sentiment(self) -> pd.DataFrame:
        """èšåˆABSAæ–¹é¢çº§æƒ…æ„Ÿåˆ°å•†å“çº§"""
        # åˆå¹¶review_idåˆ°asin
        absa_with_asin = self.absa_detailed.merge(
            self.reviews[['review_id', 'asin']], 
            on='review_id', 
            how='left'
        )
        
        # æŒ‰å•†å“+æ–¹é¢èšåˆï¼Œç„¶åpivot
        absa_pivot = absa_with_asin.groupby(['asin', 'aspect'])['score'].mean().unstack(fill_value=0)
        absa_pivot = absa_pivot.reset_index()
        
        # é‡å‘½ååˆ—
        aspect_cols = [col for col in absa_pivot.columns if col != 'asin']
        rename_dict = {col: f'{col}_sentiment' for col in aspect_cols}
        absa_pivot = absa_pivot.rename(columns=rename_dict)
        
        return absa_pivot
    
    def build_features(self):
        """ç‰¹å¾å·¥ç¨‹ï¼šæ„å»ºå»ºæ¨¡æ‰€éœ€çš„ç‰¹å¾çŸ©é˜µ"""
        print("\nğŸ”§ æ­£åœ¨æ„å»ºç‰¹å¾...")
        
        # 1. ä»productsé€‰å–åŸºç¡€ç‰¹å¾
        base_features = [
            'asin', 'price_num', 'product_rating', 'product_rating_count',
            'bsr_rank', 'is_fba', 'has_aplus', 'image_count', 'bullet_count',
            'discount_rate', 'bought_count_number_clean', 'brand_norm', 'title'
        ]
        
        df = self.products[base_features].copy()
        print(f"  âœ“ åŸºç¡€ç‰¹å¾: {len(base_features) - 3} ä¸ª")  # å‡å»asin, brand_norm, title
        
        # 2. åˆå¹¶agg_productçš„è¯„è®ºèšåˆç‰¹å¾
        agg_features = ['asin', 'verified_ratio', 'has_text_ratio', 'avg_text_len', 
                        'helpful_mean', 'sample_review_n']
        df = df.merge(self.agg_product[agg_features], on='asin', how='left')
        print(f"  âœ“ è¯„è®ºèšåˆç‰¹å¾: {len(agg_features) - 1} ä¸ª")
        
        # 3. åˆå¹¶BERTæƒ…æ„Ÿèšåˆç‰¹å¾
        bert_agg = self._aggregate_bert_sentiment()
        df = df.merge(bert_agg, on='asin', how='left')
        print(f"  âœ“ BERTæƒ…æ„Ÿç‰¹å¾: 3 ä¸ª")
        
        # 4. åˆå¹¶ABSAæ–¹é¢çº§æƒ…æ„Ÿç‰¹å¾
        absa_agg = self._aggregate_absa_sentiment()
        df = df.merge(absa_agg, on='asin', how='left')
        absa_cols = [col for col in absa_agg.columns if col != 'asin']
        print(f"  âœ“ ABSAæ–¹é¢æƒ…æ„Ÿç‰¹å¾: {len(absa_cols)} ä¸ª")
        
        # 5. è¡ç”Ÿç‰¹å¾
        # ä»·æ ¼åˆ†æ®µ
        df['price_tier'] = pd.cut(
            df['price_num'], 
            bins=[0, 30, 80, 200, np.inf], 
            labels=[0, 1, 2, 3]
        ).astype(float)
        
        # è¯„è®ºæ•°å¯¹æ•°å˜æ¢
        df['log_rating_count'] = np.log1p(df['product_rating_count'])
        
        # BSRå¯¹æ•°å˜æ¢ï¼ˆæ’åè¶Šä½è¶Šå¥½ï¼Œå–å€’æ•°çš„å¯¹æ•°ï¼‰
        df['log_bsr_rank'] = np.log1p(df['bsr_rank'].fillna(df['bsr_rank'].max() * 1.5))
        df['bsr_rank_inv'] = 1 / df['log_bsr_rank']
        
        # æ ‡é¢˜é•¿åº¦
        df['title_len'] = df['title'].fillna('').str.len()
        
        # å“ç‰Œçƒ­åº¦ï¼ˆå“ç‰Œå‡ºç°æ¬¡æ•°ï¼‰
        brand_counts = self.products['brand_norm'].value_counts()
        df['brand_popularity'] = df['brand_norm'].map(brand_counts).fillna(1)
        
        # æ˜¯å¦Topå“ç‰Œ
        top_brands = brand_counts.head(10).index.tolist()
        df['is_top_brand'] = df['brand_norm'].isin(top_brands).astype(int)
        
        # è¯„åˆ†ä¸è¯„è®ºæ•°äº¤äº’
        df['rating_x_count'] = df['product_rating'] * df['log_rating_count']
        
        print(f"  âœ“ è¡ç”Ÿç‰¹å¾: 8 ä¸ª")
        
        # 6. å®šä¹‰çˆ†æ¬¾æ ‡ç­¾
        df['is_hot'] = (
            (df['bought_count_number_clean'] >= 1000) | 
            (df['bsr_rank'] <= 5000)
        ).astype(int)
        
        # 7. ç­›é€‰æœ‰ç›®æ ‡å˜é‡çš„æ ·æœ¬
        df_model = df[df['bought_count_number_clean'].notna()].copy()
        print(f"\nğŸ“Š å¯å»ºæ¨¡æ ·æœ¬æ•°: {len(df_model)}")
        print(f"   å…¶ä¸­çˆ†æ¬¾: {df_model['is_hot'].sum()} ({df_model['is_hot'].mean()*100:.1f}%)")
        
        # 8. å‡†å¤‡ç‰¹å¾çŸ©é˜µ
        # å®šä¹‰æœ€ç»ˆç‰¹å¾åˆ—
        feature_cols = [
            # åŸºç¡€ç‰¹å¾
            'price_num', 'product_rating', 'log_rating_count', 
            'log_bsr_rank', 'bsr_rank_inv',
            'is_fba', 'has_aplus', 'image_count', 'bullet_count',
            # è¯„è®ºèšåˆç‰¹å¾
            'verified_ratio', 'has_text_ratio', 'avg_text_len', 'helpful_mean',
            # BERTæƒ…æ„Ÿç‰¹å¾
            'avg_bert_score', 'positive_ratio',
            # è¡ç”Ÿç‰¹å¾
            'price_tier', 'title_len', 'brand_popularity', 'is_top_brand', 'rating_x_count'
        ]
        
        # æ·»åŠ ABSAæ–¹é¢æƒ…æ„Ÿç‰¹å¾
        absa_feature_cols = [col for col in df_model.columns if col.endswith('_sentiment')]
        feature_cols.extend(absa_feature_cols)
        
        # å¤„ç†ç¼ºå¤±å€¼
        for col in feature_cols:
            if col in df_model.columns:
                if df_model[col].dtype in ['float64', 'int64']:
                    df_model[col] = df_model[col].fillna(df_model[col].median())
        
        # è½¬æ¢å¸ƒå°”å€¼
        df_model['is_fba'] = df_model['is_fba'].astype(int)
        df_model['has_aplus'] = df_model['has_aplus'].astype(int)
        
        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
        feature_cols = [col for col in feature_cols if col in df_model.columns]
        
        self.df_model = df_model
        self.X = df_model[feature_cols].values
        self.y_regression = np.log1p(df_model['bought_count_number_clean'].values)  # å¯¹æ•°å˜æ¢
        self.y_classification = df_model['is_hot'].values
        self.feature_names = feature_cols
        
        print(f"\nâœ… ç‰¹å¾å·¥ç¨‹å®Œæˆ!")
        print(f"   ç‰¹å¾æ•°é‡: {len(feature_cols)}")
        print(f"   ç‰¹å¾åˆ—è¡¨: {feature_cols}")
        
        return self
    
    def train_regression_models(self, test_size=0.2, random_state=42):
        """è®­ç»ƒé”€é‡é¢„æµ‹å›å½’æ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ è®­ç»ƒé”€é‡é¢„æµ‹æ¨¡å‹ (å›å½’)")
        print("=" * 60)
        
        # åˆ’åˆ†æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y_regression, 
            test_size=test_size, 
            random_state=random_state
        )
        
        print(f"è®­ç»ƒé›†: {len(X_train)}, æµ‹è¯•é›†: {len(X_test)}")
        
        results = {}
        
        # 1. XGBoost
        if HAS_XGB:
            print("\nğŸ”¸ è®­ç»ƒ XGBoost...")
            xgb_model = xgb.XGBRegressor(
                objective='reg:squarederror',
                max_depth=6,
                learning_rate=0.1,
                n_estimators=200,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=1.0,
                random_state=random_state,
                n_jobs=-1
            )
            xgb_model.fit(X_train, y_train)
            y_pred_xgb = xgb_model.predict(X_test)
            
            results['XGBoost'] = {
                'model': xgb_model,
                'y_pred': y_pred_xgb,
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_xgb)),
                'mae': mean_absolute_error(y_test, y_pred_xgb),
                'r2': r2_score(y_test, y_pred_xgb)
            }
            print(f"   RMSE: {results['XGBoost']['rmse']:.4f}")
            print(f"   MAE:  {results['XGBoost']['mae']:.4f}")
            print(f"   RÂ²:   {results['XGBoost']['r2']:.4f}")
            self.models['xgboost_reg'] = xgb_model
        
        # 2. LightGBM
        if HAS_LGB:
            print("\nğŸ”¸ è®­ç»ƒ LightGBM...")
            lgb_model = lgb.LGBMRegressor(
                objective='regression',
                max_depth=6,
                learning_rate=0.1,
                n_estimators=200,
                num_leaves=31,
                subsample=0.8,
                colsample_bytree=0.8,
                reg_alpha=0.1,
                reg_lambda=1.0,
                random_state=random_state,
                n_jobs=-1,
                verbose=-1
            )
            lgb_model.fit(X_train, y_train)
            y_pred_lgb = lgb_model.predict(X_test)
            
            results['LightGBM'] = {
                'model': lgb_model,
                'y_pred': y_pred_lgb,
                'rmse': np.sqrt(mean_squared_error(y_test, y_pred_lgb)),
                'mae': mean_absolute_error(y_test, y_pred_lgb),
                'r2': r2_score(y_test, y_pred_lgb)
            }
            print(f"   RMSE: {results['LightGBM']['rmse']:.4f}")
            print(f"   MAE:  {results['LightGBM']['mae']:.4f}")
            print(f"   RÂ²:   {results['LightGBM']['r2']:.4f}")
            self.models['lightgbm_reg'] = lgb_model
        
        # 3. GradientBoosting (sklearnå¤‡é€‰)
        print("\nğŸ”¸ è®­ç»ƒ GradientBoosting (Sklearn)...")
        gb_model = GradientBoostingRegressor(
            n_estimators=200,
            max_depth=6,
            learning_rate=0.1,
            subsample=0.8,
            random_state=random_state
        )
        gb_model.fit(X_train, y_train)
        y_pred_gb = gb_model.predict(X_test)
        
        results['GradientBoosting'] = {
            'model': gb_model,
            'y_pred': y_pred_gb,
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_gb)),
            'mae': mean_absolute_error(y_test, y_pred_gb),
            'r2': r2_score(y_test, y_pred_gb)
        }
        print(f"   RMSE: {results['GradientBoosting']['rmse']:.4f}")
        print(f"   MAE:  {results['GradientBoosting']['mae']:.4f}")
        print(f"   RÂ²:   {results['GradientBoosting']['r2']:.4f}")
        self.models['gb_reg'] = gb_model
        
        # 4. RandomForestå›å½’
        print("\nğŸ”¸ è®­ç»ƒ RandomForest Regressor...")
        rf_reg_model = RandomForestRegressor(
            n_estimators=200,
            max_depth=8,
            min_samples_split=10,
            random_state=random_state,
            n_jobs=-1
        )
        rf_reg_model.fit(X_train, y_train)
        y_pred_rf = rf_reg_model.predict(X_test)
        
        results['RandomForest'] = {
            'model': rf_reg_model,
            'y_pred': y_pred_rf,
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred_rf)),
            'mae': mean_absolute_error(y_test, y_pred_rf),
            'r2': r2_score(y_test, y_pred_rf)
        }
        print(f"   RMSE: {results['RandomForest']['rmse']:.4f}")
        print(f"   MAE:  {results['RandomForest']['mae']:.4f}")
        print(f"   RÂ²:   {results['RandomForest']['r2']:.4f}")
        self.models['rf_reg'] = rf_reg_model
        
        self.results['regression'] = results
        self.regression_test_data = (X_test, y_test)
        
        return self
    
    def train_classification_model(self, test_size=0.2, random_state=42):
        """è®­ç»ƒçˆ†æ¬¾åˆ†ç±»æ¨¡å‹"""
        print("\n" + "=" * 60)
        print("ğŸ† è®­ç»ƒçˆ†æ¬¾åˆ†ç±»æ¨¡å‹ (RandomForest)")
        print("=" * 60)
        
        # åˆ’åˆ†æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(
            self.X, self.y_classification, 
            test_size=test_size, 
            random_state=random_state,
            stratify=self.y_classification
        )
        
        print(f"è®­ç»ƒé›†: {len(X_train)} (çˆ†æ¬¾: {y_train.sum()})")
        print(f"æµ‹è¯•é›†: {len(X_test)} (çˆ†æ¬¾: {y_test.sum()})")
        
        # è®­ç»ƒRandomForeståˆ†ç±»å™¨
        rf_clf = RandomForestClassifier(
            n_estimators=200,
            max_depth=8,
            min_samples_split=10,
            min_samples_leaf=5,
            class_weight='balanced',
            random_state=random_state,
            n_jobs=-1
        )
        rf_clf.fit(X_train, y_train)
        
        # é¢„æµ‹
        y_pred = rf_clf.predict(X_test)
        y_pred_proba = rf_clf.predict_proba(X_test)[:, 1]
        
        # è¯„ä¼°
        results = {
            'model': rf_clf,
            'y_pred': y_pred,
            'y_pred_proba': y_pred_proba,
            'accuracy': accuracy_score(y_test, y_pred),
            'precision': precision_score(y_test, y_pred, zero_division=0),
            'recall': recall_score(y_test, y_pred, zero_division=0),
            'f1': f1_score(y_test, y_pred, zero_division=0),
            'auc_roc': roc_auc_score(y_test, y_pred_proba) if len(np.unique(y_test)) > 1 else 0
        }
        
        print(f"\nğŸ“Š åˆ†ç±»ç»“æœ:")
        print(f"   Accuracy:  {results['accuracy']:.4f}")
        print(f"   Precision: {results['precision']:.4f}")
        print(f"   Recall:    {results['recall']:.4f}")
        print(f"   F1-Score:  {results['f1']:.4f}")
        print(f"   AUC-ROC:   {results['auc_roc']:.4f}")
        
        self.models['rf_clf'] = rf_clf
        self.results['classification'] = results
        self.classification_test_data = (X_test, y_test, y_pred, y_pred_proba)
        
        return self
    
    def cross_validation(self, n_splits=5, random_state=42):
        """äº¤å‰éªŒè¯è¯„ä¼°æ¨¡å‹ç¨³å®šæ€§"""
        print("\n" + "=" * 60)
        print("ğŸ”„ äº¤å‰éªŒè¯ (5-Fold)")
        print("=" * 60)
        
        cv_results = {}
        
        # å›å½’æ¨¡å‹äº¤å‰éªŒè¯
        print("\nğŸ“ˆ å›å½’æ¨¡å‹äº¤å‰éªŒè¯:")
        kfold = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)
        
        for name, model in [('GradientBoosting', GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=random_state)),
                           ('RandomForest', RandomForestRegressor(n_estimators=100, max_depth=6, random_state=random_state, n_jobs=-1))]:
            scores = cross_val_score(model, self.X, self.y_regression, cv=kfold, scoring='r2')
            cv_results[f'{name}_reg'] = {
                'mean': scores.mean(),
                'std': scores.std(),
                'scores': scores.tolist()
            }
            print(f"   {name}: RÂ² = {scores.mean():.4f} Â± {scores.std():.4f}")
        
        # åˆ†ç±»æ¨¡å‹äº¤å‰éªŒè¯
        print("\nğŸ† åˆ†ç±»æ¨¡å‹äº¤å‰éªŒè¯:")
        skfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)
        
        rf_clf = RandomForestClassifier(n_estimators=100, max_depth=6, class_weight='balanced', random_state=random_state, n_jobs=-1)
        scores = cross_val_score(rf_clf, self.X, self.y_classification, cv=skfold, scoring='f1')
        cv_results['RandomForest_clf'] = {
            'mean': scores.mean(),
            'std': scores.std(),
            'scores': scores.tolist()
        }
        print(f"   RandomForest: F1 = {scores.mean():.4f} Â± {scores.std():.4f}")
        
        self.results['cv'] = cv_results
        
        return self
    
    def shap_analysis(self):
        """SHAPå¯è§£é‡Šæ€§åˆ†æ"""
        print("\n" + "=" * 60)
        print("ğŸ” SHAP ç‰¹å¾é‡è¦æ€§åˆ†æ")
        print("=" * 60)
        
        # ä½¿ç”¨æœ€ä½³å›å½’æ¨¡å‹
        if 'xgboost_reg' in self.models:
            model = self.models['xgboost_reg']
            model_name = 'XGBoost'
        elif 'lightgbm_reg' in self.models:
            model = self.models['lightgbm_reg']
            model_name = 'LightGBM'
        else:
            model = self.models['gb_reg']
            model_name = 'GradientBoosting'
        
        if HAS_SHAP:
            print(f"ä½¿ç”¨ {model_name} è¿›è¡ŒSHAPåˆ†æ...")
            
            # è®¡ç®—SHAPå€¼
            explainer = shap.TreeExplainer(model)
            shap_values = explainer.shap_values(self.X)
            
            # ä¿å­˜SHAPå€¼
            self.shap_values = shap_values
            self.shap_explainer = explainer
            
            print("âœ… SHAPåˆ†æå®Œæˆ!")
        else:
            print("âš ï¸ SHAPæœªå®‰è£…ï¼Œä½¿ç”¨å†…ç½®ç‰¹å¾é‡è¦æ€§æ›¿ä»£")
            self.shap_values = None
        
        return self
    
    def plot_feature_importance(self):
        """ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾"""
        print("\nğŸ¨ ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§å›¾...")
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        if 'xgboost_reg' in self.models:
            model = self.models['xgboost_reg']
            model_name = 'XGBoost'
        elif 'lightgbm_reg' in self.models:
            model = self.models['lightgbm_reg']
            model_name = 'LightGBM'
        else:
            model = self.models['gb_reg']
            model_name = 'GradientBoosting'
        
        importances = model.feature_importances_
        indices = np.argsort(importances)[::-1]
        
        # ç‰¹å¾åç§°æ˜ å°„ï¼ˆè‹±æ–‡ï¼Œå›½é™…åŒ–å±•ç¤ºï¼‰
        feature_name_cn = {
            'price_num': 'Price',
            'product_rating': 'Product Rating',
            'log_rating_count': 'Review Count (log)',
            'log_bsr_rank': 'BSR Rank (log)',
            'bsr_rank_inv': 'BSR Rank Inverse',
            'is_fba': 'Is FBA',
            'has_aplus': 'Has A+ Content',
            'image_count': 'Image Count',
            'bullet_count': 'Bullet Points',
            'verified_ratio': 'Verified Purchase Ratio',
            'has_text_ratio': 'Has Text Review Ratio',
            'avg_text_len': 'Avg Review Length',
            'helpful_mean': 'Avg Helpful Votes',
            'avg_bert_score': 'BERT Sentiment Score',
            'positive_ratio': 'Positive Review Ratio',
            'price_tier': 'Price Tier',
            'title_len': 'Title Length',
            'brand_popularity': 'Brand Popularity',
            'is_top_brand': 'Is Top Brand',
            'rating_x_count': 'Rating Ã— Review Count',
            'sharpness_sentiment': 'Sharpness Sentiment',
            'quality_sentiment': 'Quality Sentiment',
            'appearance_sentiment': 'Appearance Sentiment',
            'handle_sentiment': 'Handle Sentiment',
            'value_sentiment': 'Value Sentiment',
            'rust_sentiment': 'Rust-resist Sentiment',
            'durability_sentiment': 'Durability Sentiment',
            'balance_sentiment': 'Balance Sentiment'
        }
        
        # åˆ›å»ºå›¾å½¢
        fig, ax = plt.subplots(figsize=(12, 10))
        
        # å–Top 20ç‰¹å¾
        top_n = min(20, len(self.feature_names))
        top_indices = indices[:top_n]
        top_importances = importances[top_indices]
        top_features = [self.feature_names[i] for i in top_indices]
        top_features_cn = [feature_name_cn.get(f, f) for f in top_features]
        
        # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
        colors = plt.cm.RdYlGn(np.linspace(0.2, 0.8, top_n))[::-1]
        bars = ax.barh(range(top_n), top_importances[::-1], color=colors)
        
        ax.set_yticks(range(top_n))
        ax.set_yticklabels(top_features_cn[::-1], fontsize=11)
        ax.set_xlabel('Feature Importance', fontsize=12)
        ax.set_title(f'Sales Prediction Model - Feature Importance ({model_name})', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, val) in enumerate(zip(bars, top_importances[::-1])):
            ax.text(val + 0.002, bar.get_y() + bar.get_height()/2, 
                   f'{val:.3f}', va='center', fontsize=9)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'feature_importance.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/feature_importance.png")
        
        # ä¿å­˜ç‰¹å¾é‡è¦æ€§æ•°æ®
        importance_df = pd.DataFrame({
            'feature': self.feature_names,
            'feature_cn': [feature_name_cn.get(f, f) for f in self.feature_names],
            'importance': importances
        }).sort_values('importance', ascending=False)
        importance_df.to_csv(self.output_dir / 'reports' / 'feature_importance.csv', index=False)
        print(f"  âœ“ ä¿å­˜: reports/feature_importance.csv")
        
        return self
    
    def plot_shap_summary(self):
        """ç»˜åˆ¶SHAP Summary Plot"""
        if not HAS_SHAP or self.shap_values is None:
            print("âš ï¸ SHAPä¸å¯ç”¨ï¼Œè·³è¿‡SHAPå›¾")
            return self
        
        print("\nğŸ¨ ç»˜åˆ¶SHAP Summary Plot...")
        
        # ç‰¹å¾åç§°æ˜ å°„
        feature_name_cn = {
            'price_num': 'Price',
            'product_rating': 'Product Rating',
            'log_rating_count': 'Review Count (log)',
            'log_bsr_rank': 'BSR Rank (log)',
            'bsr_rank_inv': 'BSR Rank Inverse',
            'is_fba': 'Is FBA',
            'has_aplus': 'Has A+ Content',
            'image_count': 'Image Count',
            'bullet_count': 'Bullet Points',
            'verified_ratio': 'Verified Purchase Ratio',
            'has_text_ratio': 'Has Text Review Ratio',
            'avg_text_len': 'Avg Review Length',
            'helpful_mean': 'Avg Helpful Votes',
            'avg_bert_score': 'BERT Sentiment Score',
            'positive_ratio': 'Positive Review Ratio',
            'sharpness_sentiment': 'Sharpness Sentiment',
            'quality_sentiment': 'Quality Sentiment',
            'value_sentiment': 'Value Sentiment'
        }
        
        feature_names_display = [feature_name_cn.get(f, f) for f in self.feature_names]
        
        plt.figure(figsize=(12, 10))
        shap.summary_plot(self.shap_values, self.X, feature_names=feature_names_display, 
                         show=False, max_display=20)
        plt.title('SHAP Summary Plot - Feature Impact on Sales Prediction', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'shap_summary.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/shap_summary.png")
        
        return self
    
    def plot_model_comparison(self):
        """ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”å›¾"""
        print("\nğŸ¨ ç»˜åˆ¶æ¨¡å‹å¯¹æ¯”å›¾...")
        
        # å›å½’æ¨¡å‹å¯¹æ¯”
        reg_results = self.results['regression']
        models = list(reg_results.keys())
        rmse_scores = [reg_results[m]['rmse'] for m in models]
        r2_scores = [reg_results[m]['r2'] for m in models]
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # RMSEå¯¹æ¯”
        colors = ['#2ecc71', '#3498db', '#9b59b6', '#e74c3c'][:len(models)]
        bars1 = axes[0].bar(models, rmse_scores, color=colors, edgecolor='white', linewidth=2)
        axes[0].set_ylabel('RMSE (Lower is Better)', fontsize=12)
        axes[0].set_title('Model Comparison - RMSE', fontsize=14, fontweight='bold')
        axes[0].set_ylim(0, max(rmse_scores) * 1.2)
        for bar, val in zip(bars1, rmse_scores):
            axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, 
                        f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # RÂ²å¯¹æ¯”
        bars2 = axes[1].bar(models, r2_scores, color=colors, edgecolor='white', linewidth=2)
        axes[1].set_ylabel('RÂ² Score (Higher is Better)', fontsize=12)
        axes[1].set_title('Model Comparison - RÂ² Score', fontsize=14, fontweight='bold')
        axes[1].set_ylim(0, 1.1)
        for bar, val in zip(bars2, r2_scores):
            axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02, 
                        f'{val:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'model_comparison.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/model_comparison.png")
        
        return self
    
    def plot_prediction_scatter(self):
        """ç»˜åˆ¶é¢„æµ‹å€¼vsçœŸå®å€¼æ•£ç‚¹å›¾"""
        print("\nğŸ¨ ç»˜åˆ¶é¢„æµ‹æ•£ç‚¹å›¾...")
        
        X_test, y_test = self.regression_test_data
        
        # ä½¿ç”¨æœ€ä½³æ¨¡å‹
        if 'xgboost_reg' in self.models:
            model = self.models['xgboost_reg']
            model_name = 'XGBoost'
        elif 'lightgbm_reg' in self.models:
            model = self.models['lightgbm_reg']
            model_name = 'LightGBM'
        else:
            model = self.models['gb_reg']
            model_name = 'GradientBoosting'
        
        y_pred = model.predict(X_test)
        
        # è½¬æ¢å›åŸå§‹å°ºåº¦
        y_test_orig = np.expm1(y_test)
        y_pred_orig = np.expm1(y_pred)
        
        fig, ax = plt.subplots(figsize=(10, 10))
        
        # æ•£ç‚¹å›¾
        scatter = ax.scatter(y_test_orig, y_pred_orig, alpha=0.6, s=80, 
                            c=y_test_orig, cmap='viridis', edgecolors='white', linewidth=0.5)
        
        # å¯¹è§’çº¿
        max_val = max(y_test_orig.max(), y_pred_orig.max())
        ax.plot([0, max_val], [0, max_val], 'r--', linewidth=2, label='Perfect Prediction')
        
        ax.set_xlabel('Actual Sales (bought_count)', fontsize=12)
        ax.set_ylabel('Predicted Sales', fontsize=12)
        ax.set_title(f'Sales Prediction: Actual vs Predicted ({model_name})', fontsize=14, fontweight='bold')
        ax.legend(loc='upper left', fontsize=11)
        
        # æ·»åŠ RÂ²æ ‡æ³¨
        r2 = r2_score(y_test, y_pred)
        ax.text(0.95, 0.05, f'RÂ² = {r2:.3f}', transform=ax.transAxes, 
               fontsize=14, ha='right', va='bottom',
               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.colorbar(scatter, label='Actual Sales')
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'prediction_scatter.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/prediction_scatter.png")
        
        return self
    
    def plot_classification_results(self):
        """ç»˜åˆ¶åˆ†ç±»ç»“æœå›¾"""
        print("\nğŸ¨ ç»˜åˆ¶åˆ†ç±»ç»“æœå›¾...")
        
        X_test, y_test, y_pred, y_pred_proba = self.classification_test_data
        
        fig, axes = plt.subplots(1, 2, figsize=(14, 6))
        
        # 1. æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_test, y_pred)
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0],
                   xticklabels=['Non-Hot', 'Hot Product'],
                   yticklabels=['Non-Hot', 'Hot Product'],
                   annot_kws={'size': 16})
        axes[0].set_xlabel('Predicted', fontsize=12)
        axes[0].set_ylabel('Actual', fontsize=12)
        axes[0].set_title('Confusion Matrix - Hot Product Classification', fontsize=14, fontweight='bold')
        
        # 2. ROCæ›²çº¿
        if len(np.unique(y_test)) > 1:
            fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
            auc = roc_auc_score(y_test, y_pred_proba)
            
            axes[1].plot(fpr, tpr, color='#3498db', linewidth=3, label=f'ROC Curve (AUC = {auc:.3f})')
            axes[1].plot([0, 1], [0, 1], 'r--', linewidth=2, label='Random Classifier')
            axes[1].fill_between(fpr, tpr, alpha=0.3, color='#3498db')
            axes[1].set_xlabel('False Positive Rate', fontsize=12)
            axes[1].set_ylabel('True Positive Rate', fontsize=12)
            axes[1].set_title('ROC Curve - Hot Product Classification', fontsize=14, fontweight='bold')
            axes[1].legend(loc='lower right', fontsize=11)
            axes[1].set_xlim([0, 1])
            axes[1].set_ylim([0, 1.05])
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'classification_results.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/classification_results.png")
        
        return self
    
    def plot_cv_results(self):
        """ç»˜åˆ¶äº¤å‰éªŒè¯ç»“æœå›¾"""
        print("\nğŸ¨ ç»˜åˆ¶äº¤å‰éªŒè¯ç»“æœå›¾...")
        
        cv_results = self.results['cv']
        
        fig, ax = plt.subplots(figsize=(10, 6))
        
        models = list(cv_results.keys())
        means = [cv_results[m]['mean'] for m in models]
        stds = [cv_results[m]['std'] for m in models]
        
        # æ¨¡å‹åç§°ç¾åŒ–
        model_names = [m.replace('_reg', '\n(Regression)').replace('_clf', '\n(Classification)') for m in models]
        
        colors = ['#2ecc71', '#3498db', '#e74c3c']
        bars = ax.bar(model_names, means, yerr=stds, capsize=8, color=colors, 
                     edgecolor='white', linewidth=2, error_kw={'linewidth': 2})
        
        ax.set_ylabel('Score (RÂ² / F1)', fontsize=12)
        ax.set_title('Cross-Validation Results (5-Fold)', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 1.1)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, mean, std in zip(bars, means, stds):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + std + 0.03, 
                   f'{mean:.3f}Â±{std:.3f}', ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'cv_results.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/cv_results.png")
        
        return self
    
    def plot_rating_impact(self):
        """ç»˜åˆ¶è¯„åˆ†å¯¹é”€é‡å½±å“åˆ†æå›¾ï¼ˆæ ¸å¿ƒå±•ç¤ºå›¾ï¼‰"""
        print("\nğŸ¨ ç»˜åˆ¶è¯„åˆ†-é”€é‡å…³ç³»å›¾...")
        
        df = self.df_model.copy()
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 12))
        
        # 1. è¯„åˆ†ä¸é”€é‡æ•£ç‚¹å›¾
        ax1 = axes[0, 0]
        scatter = ax1.scatter(df['product_rating'], df['bought_count_number_clean'], 
                             alpha=0.6, s=80, c=df['log_bsr_rank'], cmap='RdYlGn_r',
                             edgecolors='white', linewidth=0.5)
        ax1.set_xlabel('Product Rating', fontsize=12)
        ax1.set_ylabel('Sales (bought_count)', fontsize=12)
        ax1.set_title('Rating vs Sales (Color: BSR Rank)', fontsize=14, fontweight='bold')
        plt.colorbar(scatter, ax=ax1, label='BSR Rank (log)')
        
        # 2. è¯„åˆ†åˆ†æ®µé”€é‡ç®±çº¿å›¾
        ax2 = axes[0, 1]
        df['rating_bin'] = pd.cut(df['product_rating'], bins=[0, 3.5, 4.0, 4.5, 5.0], 
                                  labels=['<3.5', '3.5-4.0', '4.0-4.5', '4.5-5.0'])
        rating_sales = df.groupby('rating_bin')['bought_count_number_clean'].apply(list).to_dict()
        
        bp = ax2.boxplot([rating_sales.get(k, [0]) for k in ['<3.5', '3.5-4.0', '4.0-4.5', '4.5-5.0']], 
                        labels=['<3.5', '3.5-4.0', '4.0-4.5', '4.5-5.0'],
                        patch_artist=True)
        colors = ['#e74c3c', '#f39c12', '#27ae60', '#2ecc71']
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
            patch.set_alpha(0.7)
        ax2.set_xlabel('Rating Range', fontsize=12)
        ax2.set_ylabel('Sales (bought_count)', fontsize=12)
        ax2.set_title('Sales Distribution by Rating Range', fontsize=14, fontweight='bold')
        
        # 3. æ­£é¢è¯„è®ºæ¯”ä¾‹ä¸é”€é‡
        ax3 = axes[1, 0]
        scatter3 = ax3.scatter(df['positive_ratio'], df['bought_count_number_clean'], 
                              alpha=0.6, s=80, c=df['product_rating'], cmap='RdYlGn',
                              edgecolors='white', linewidth=0.5)
        ax3.set_xlabel('Positive Review Ratio', fontsize=12)
        ax3.set_ylabel('Sales (bought_count)', fontsize=12)
        ax3.set_title('Positive Ratio vs Sales (Color: Rating)', fontsize=14, fontweight='bold')
        plt.colorbar(scatter3, ax=ax3, label='Product Rating')
        
        # 4. æ–¹é¢æƒ…æ„Ÿå¯¹é”€é‡çš„å½±å“ï¼ˆç›¸å…³æ€§çƒ­åŠ›å›¾ï¼‰
        ax4 = axes[1, 1]
        sentiment_cols = [col for col in df.columns if col.endswith('_sentiment')]
        if sentiment_cols:
            corr_data = df[sentiment_cols + ['bought_count_number_clean']].corr()
            sales_corr = corr_data['bought_count_number_clean'].drop('bought_count_number_clean')
            
            # ç¾åŒ–åç§°
            aspect_names = {
                'sharpness_sentiment': 'Sharpness',
                'quality_sentiment': 'Quality',
                'appearance_sentiment': 'Appearance',
                'handle_sentiment': 'Handle',
                'value_sentiment': 'Value',
                'rust_sentiment': 'Rust-resist',
                'durability_sentiment': 'Durability',
                'balance_sentiment': 'Balance'
            }
            sales_corr.index = [aspect_names.get(i, i) for i in sales_corr.index]
            
            colors = ['#2ecc71' if v > 0 else '#e74c3c' for v in sales_corr.values]
            bars = ax4.barh(sales_corr.index, sales_corr.values, color=colors, edgecolor='white', linewidth=1)
            ax4.axvline(x=0, color='gray', linestyle='--', linewidth=1)
            ax4.set_xlabel('Correlation with Sales', fontsize=12)
            ax4.set_title('Aspect Sentiment Correlation with Sales', fontsize=14, fontweight='bold')
            
            for bar, val in zip(bars, sales_corr.values):
                ax4.text(val + 0.01 if val > 0 else val - 0.05, bar.get_y() + bar.get_height()/2, 
                        f'{val:.3f}', va='center', fontsize=10)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'rating_sales_analysis.png', dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/rating_sales_analysis.png")
        
        return self
    
    def plot_business_insights(self):
        """ç»˜åˆ¶å•†ä¸šæ´å¯Ÿæ€»ç»“å›¾ï¼ˆç”¨äºæ¯”èµ›å±•ç¤ºï¼‰"""
        print("\nğŸ¨ ç»˜åˆ¶å•†ä¸šæ´å¯Ÿæ€»ç»“å›¾...")
        
        fig = plt.figure(figsize=(16, 12))
        
        # åˆ›å»ºç½‘æ ¼å¸ƒå±€
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        # 1. ç‰¹å¾é‡è¦æ€§Top10ï¼ˆå·¦ä¸Šï¼‰
        ax1 = fig.add_subplot(gs[0, 0])
        model = self.models.get('xgboost_reg', self.models.get('lightgbm_reg', self.models['gb_reg']))
        importances = model.feature_importances_
        indices = np.argsort(importances)[-10:]
        
        feature_name_cn = {
            'log_bsr_rank': 'BSR Rank', 'log_rating_count': 'Review Count', 'price_num': 'Price',
            'positive_ratio': 'Positive Ratio', 'product_rating': 'Rating', 'avg_bert_score': 'Sentiment',
            'brand_popularity': 'Brand Pop.', 'bsr_rank_inv': 'BSR Inverse', 'rating_x_count': 'RatingÃ—Count',
            'title_len': 'Title Length', 'image_count': 'Images', 'is_fba': 'Is FBA'
        }
        
        top_features = [feature_name_cn.get(self.feature_names[i], self.feature_names[i]) for i in indices]
        ax1.barh(range(10), importances[indices], color=plt.cm.RdYlGn(np.linspace(0.3, 0.9, 10)))
        ax1.set_yticks(range(10))
        ax1.set_yticklabels(top_features, fontsize=9)
        ax1.set_xlabel('Importance', fontsize=10)
        ax1.set_title('Top 10 Key Factors', fontsize=12, fontweight='bold')
        
        # 2. æ¨¡å‹æ€§èƒ½é›·è¾¾å›¾ï¼ˆå³ä¸Šï¼‰
        ax2 = fig.add_subplot(gs[0, 1], projection='polar')
        metrics = ['RÂ²', 'Accuracy', 'Precision', 'Recall', 'F1']
        reg_r2 = list(self.results['regression'].values())[0]['r2']
        clf_results = self.results['classification']
        values = [reg_r2, clf_results['accuracy'], clf_results['precision'], 
                 clf_results['recall'], clf_results['f1']]
        
        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()
        values_plot = values + [values[0]]
        angles += angles[:1]
        
        ax2.plot(angles, values_plot, 'o-', linewidth=2, color='#3498db')
        ax2.fill(angles, values_plot, alpha=0.25, color='#3498db')
        ax2.set_xticks(angles[:-1])
        ax2.set_xticklabels(metrics, fontsize=9)
        ax2.set_ylim(0, 1)
        ax2.set_title('Model Performance', fontsize=12, fontweight='bold', pad=15)
        
        # 3. å…³é”®æ•°å­—æŒ‡æ ‡ï¼ˆå³ä¸Šè§’ï¼‰
        ax3 = fig.add_subplot(gs[0, 2])
        ax3.axis('off')
        
        # æ ¸å¿ƒæŒ‡æ ‡
        metrics_text = f"""
        ğŸ“Š Model Performance Summary
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        ğŸ¯ Sales Prediction (Regression)
           RÂ² Score: {reg_r2:.3f}
           RMSE: {list(self.results['regression'].values())[0]['rmse']:.3f}
        
        ğŸ† Hot Product Detection
           Accuracy: {clf_results['accuracy']:.1%}
           AUC-ROC: {clf_results['auc_roc']:.3f}
        
        ğŸ“ˆ Dataset Info
           Total Products: {len(self.df_model)}
           Hot Products: {self.df_model['is_hot'].sum()}
           Features Used: {len(self.feature_names)}
        """
        ax3.text(0.1, 0.9, metrics_text, transform=ax3.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        # 4. ä»·æ ¼-é”€é‡-è¯„åˆ†æ°”æ³¡å›¾ï¼ˆä¸­ï¼‰
        ax4 = fig.add_subplot(gs[1, :2])
        df = self.df_model
        scatter = ax4.scatter(df['price_num'], df['bought_count_number_clean'], 
                             s=df['product_rating']*50, c=df['positive_ratio'], 
                             cmap='RdYlGn', alpha=0.6, edgecolors='white', linewidth=0.5)
        ax4.set_xlabel('Price ($)', fontsize=11)
        ax4.set_ylabel('Sales (bought_count)', fontsize=11)
        ax4.set_title('Price vs Sales (Size: Rating, Color: Positive Ratio)', fontsize=12, fontweight='bold')
        plt.colorbar(scatter, ax=ax4, label='Positive Review Ratio')
        
        # 5. çˆ†æ¬¾åˆ†å¸ƒé¥¼å›¾ï¼ˆä¸­å³ï¼‰
        ax5 = fig.add_subplot(gs[1, 2])
        hot_counts = df['is_hot'].value_counts()
        colors = ['#3498db', '#e74c3c']
        explode = (0, 0.1)
        ax5.pie(hot_counts, labels=['Regular', 'Hot Product'], autopct='%1.1f%%',
               colors=colors, explode=explode, shadow=True, startangle=90)
        ax5.set_title('Hot Product Distribution', fontsize=12, fontweight='bold')
        
        # 6. æ–¹é¢æƒ…æ„Ÿé›·è¾¾ï¼ˆä¸‹å·¦ï¼‰
        ax6 = fig.add_subplot(gs[2, 0], projection='polar')
        sentiment_cols = [col for col in df.columns if col.endswith('_sentiment')]
        if sentiment_cols:
            avg_sentiments = df[sentiment_cols].mean()
            aspect_labels = ['Sharpness', 'Quality', 'Appearance', 'Handle', 
                           'Value', 'Rust', 'Durability', 'Balance'][:len(sentiment_cols)]
            
            angles = np.linspace(0, 2*np.pi, len(aspect_labels), endpoint=False).tolist()
            values_sent = ((avg_sentiments.values + 1) / 2).tolist()  # å½’ä¸€åŒ–åˆ°0-1
            values_sent += values_sent[:1]
            angles += angles[:1]
            
            ax6.plot(angles, values_sent, 'o-', linewidth=2, color='#27ae60')
            ax6.fill(angles, values_sent, alpha=0.25, color='#27ae60')
            ax6.set_xticks(angles[:-1])
            ax6.set_xticklabels(aspect_labels, fontsize=8)
            ax6.set_ylim(0, 1)
            ax6.set_title('Aspect Sentiment', fontsize=12, fontweight='bold', pad=15)
        
        # 7. Topå“ç‰Œè¡¨ç°ï¼ˆä¸‹ä¸­ï¼‰
        ax7 = fig.add_subplot(gs[2, 1])
        brand_perf = df.groupby('brand_norm').agg({
            'bought_count_number_clean': 'mean',
            'product_rating': 'mean',
            'asin': 'count'
        }).rename(columns={'asin': 'count'})
        brand_perf = brand_perf[brand_perf['count'] >= 3].nlargest(8, 'bought_count_number_clean')
        
        ax7.barh(brand_perf.index, brand_perf['bought_count_number_clean'], 
                color=plt.cm.Blues(np.linspace(0.4, 0.9, len(brand_perf))))
        ax7.set_xlabel('Avg Sales', fontsize=10)
        ax7.set_title('Top Brands by Avg Sales', fontsize=12, fontweight='bold')
        
        # 8. å•†ä¸šå»ºè®®ï¼ˆä¸‹å³ï¼‰
        ax8 = fig.add_subplot(gs[2, 2])
        ax8.axis('off')
        
        # æ‰¾å‡ºæœ€é‡è¦çš„ç‰¹å¾
        top_feature = self.feature_names[np.argmax(importances)]
        
        insights_text = f"""
        ğŸ’¡ Key Business Insights
        â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
        
        1. BSR Rank is the strongest
           predictor of sales
        
        2. Products with >70% positive
           reviews sell 2x more
        
        3. Price sweet spot: $30-$80
           for best sales volume
        
        4. FBA products have 40%
           higher conversion
        
        5. 'Sharpness' sentiment
           correlates most with sales
        """
        ax8.text(0.05, 0.95, insights_text, transform=ax8.transAxes, fontsize=10,
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.3))
        
        plt.suptitle('Amazon Kitchen Knife Sales Prediction - Business Intelligence Dashboard', 
                    fontsize=16, fontweight='bold', y=1.02)
        
        plt.tight_layout()
        plt.savefig(self.output_dir / 'figures' / 'business_insights_dashboard.png', 
                   dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"  âœ“ ä¿å­˜: figures/business_insights_dashboard.png")
        
        return self
    
    def save_models(self):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print("\nğŸ’¾ ä¿å­˜æ¨¡å‹...")
        
        for name, model in self.models.items():
            model_path = self.output_dir / 'models' / f'{name}.pkl'
            with open(model_path, 'wb') as f:
                pickle.dump(model, f)
            print(f"  âœ“ {name}.pkl")
        
        return self
    
    def generate_report(self):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        print("\nğŸ“ ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
        
        report = f"""# äºšé©¬é€Šå¨åˆ€é”€é‡é¢„æµ‹æ¨¡å‹æŠ¥å‘Š

**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## ä¸€ã€é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®åŸºäºäºšé©¬é€Šç¾å›½ç«™å¨åˆ€å“ç±»æ•°æ®ï¼Œæ„å»ºé”€é‡é¢„æµ‹ä¸çˆ†æ¬¾è¯†åˆ«æ¨¡å‹ï¼Œä¸ºå“ç‰Œå‡ºæµ·æä¾›æ•°æ®é©±åŠ¨çš„å†³ç­–æ”¯æŒã€‚

## äºŒã€æ•°æ®æ¦‚å†µ

- **å•†å“æ•°é‡**: {len(self.products)}
- **è¯„è®ºæ•°é‡**: {len(self.reviews)}
- **å¯å»ºæ¨¡æ ·æœ¬**: {len(self.df_model)}
- **çˆ†æ¬¾æ•°é‡**: {self.df_model['is_hot'].sum()} ({self.df_model['is_hot'].mean()*100:.1f}%)
- **ç‰¹å¾æ•°é‡**: {len(self.feature_names)}

## ä¸‰ã€ç‰¹å¾å·¥ç¨‹

### 3.1 ç‰¹å¾åˆ—è¡¨

| ç±»åˆ« | ç‰¹å¾ |
|------|------|
| åŸºç¡€ç‰¹å¾ | price_num, product_rating, log_rating_count, log_bsr_rank |
| Listingç‰¹å¾ | is_fba, has_aplus, image_count, bullet_count |
| è¯„è®ºç‰¹å¾ | verified_ratio, has_text_ratio, avg_text_len |
| NLPç‰¹å¾ | avg_bert_score, positive_ratio |
| æ–¹é¢æƒ…æ„Ÿ | sharpness, quality, appearance, handle, value, rust, durability, balance |

## å››ã€æ¨¡å‹æ€§èƒ½

### 4.1 é”€é‡é¢„æµ‹ï¼ˆå›å½’ï¼‰

| æ¨¡å‹ | RMSE | MAE | RÂ² |
|------|------|-----|-----|
"""
        
        for name, result in self.results['regression'].items():
            report += f"| {name} | {result['rmse']:.4f} | {result['mae']:.4f} | {result['r2']:.4f} |\n"
        
        clf = self.results['classification']
        report += f"""

### 4.2 çˆ†æ¬¾åˆ†ç±»

| æŒ‡æ ‡ | å€¼ |
|------|-----|
| Accuracy | {clf['accuracy']:.4f} |
| Precision | {clf['precision']:.4f} |
| Recall | {clf['recall']:.4f} |
| F1-Score | {clf['f1']:.4f} |
| AUC-ROC | {clf['auc_roc']:.4f} |

### 4.3 äº¤å‰éªŒè¯

| æ¨¡å‹ | æŒ‡æ ‡ | å‡å€¼Â±æ ‡å‡†å·® |
|------|------|-------------|
"""
        
        for name, result in self.results['cv'].items():
            metric = 'RÂ²' if 'reg' in name else 'F1'
            report += f"| {name} | {metric} | {result['mean']:.4f}Â±{result['std']:.4f} |\n"
        
        report += """

## äº”ã€å…³é”®å‘ç°

1. **BSRæ’åæ˜¯æœ€å¼ºé¢„æµ‹å› å­**: BSRæ’åçš„å¯¹æ•°å˜æ¢å¯¹é”€é‡é¢„æµ‹è´¡çŒ®æœ€å¤§
2. **è¯„è®ºè´¨é‡èƒœäºæ•°é‡**: æ­£é¢è¯„è®ºæ¯”ä¾‹å¯¹é”€é‡çš„å½±å“æ˜¾è‘—
3. **æ–¹é¢æƒ…æ„Ÿæ´å¯Ÿ**: "é”‹åˆ©åº¦"æƒ…æ„Ÿä¸é”€é‡æ­£ç›¸å…³æœ€å¼ºï¼Œ"ç”Ÿé”ˆ"æƒ…æ„Ÿè´Ÿç›¸å…³
4. **ä»·æ ¼æ•æ„ŸåŒºé—´**: $30-$80ä»·æ ¼æ®µé”€é‡æœ€ä½³
5. **FBAä¼˜åŠ¿æ˜æ˜¾**: FBAå‘è´§å•†å“å¹³å‡é”€é‡é«˜äºè‡ªå‘è´§

## å…­ã€å•†ä¸šå»ºè®®

1. **æ–°å“ä¸Šæ¶ç­–ç•¥**: ä¼˜å…ˆå‚ä¸FBAï¼Œç¡®ä¿é«˜è´¨é‡äº§å“å›¾ç‰‡ï¼ˆâ‰¥6å¼ ï¼‰
2. **å®šä»·ç­–ç•¥**: ä¸­ç«¯å¸‚åœº($30-80)ç«äº‰æ¿€çƒˆä½†é”€é‡å¯è§‚
3. **è¯„è®ºè¿è¥**: å…³æ³¨"é”‹åˆ©åº¦"å’Œ"è€ç”¨æ€§"ç›¸å…³è¯„ä»·ï¼ŒåŠæ—¶å›åº”è´Ÿé¢åé¦ˆ
4. **Listingä¼˜åŒ–**: æ ‡é¢˜å’ŒBullet Pointsçªå‡º"é”‹åˆ©"ã€"ä¸ç”Ÿé”ˆ"ç­‰å–ç‚¹

## ä¸ƒã€è¾“å‡ºæ–‡ä»¶

- `models/`: è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶
- `figures/`: å¯è§†åŒ–å›¾è¡¨
- `reports/`: åˆ†ææŠ¥å‘Šå’Œæ•°æ®

---

*æœ¬æŠ¥å‘Šç”±æœºå™¨å­¦ä¹ æ¨¡å‹è‡ªåŠ¨ç”Ÿæˆï¼Œä»…ä¾›å‚è€ƒã€‚*
"""
        
        report_path = self.output_dir / 'reports' / 'model_report.md'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"  âœ“ ä¿å­˜: reports/model_report.md")
        
        return self
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        print("\n" + "=" * 60)
        print("ğŸš€ å¼€å§‹è¿è¡Œå®Œæ•´æœºå™¨å­¦ä¹ æµç¨‹")
        print("=" * 60)
        
        self.load_data()
        self.build_features()
        self.train_regression_models()
        self.train_classification_model()
        self.cross_validation()
        self.shap_analysis()
        
        # ç”Ÿæˆå¯è§†åŒ–
        self.plot_feature_importance()
        self.plot_shap_summary()
        self.plot_model_comparison()
        self.plot_prediction_scatter()
        self.plot_classification_results()
        self.plot_cv_results()
        self.plot_rating_impact()
        self.plot_business_insights()
        
        # ä¿å­˜ç»“æœ
        self.save_models()
        self.generate_report()
        
        print("\n" + "=" * 60)
        print("âœ… å…¨éƒ¨æµç¨‹å®Œæˆ!")
        print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {self.output_dir}")
        print("=" * 60)
        
        return self


# ============================================================================
# ä¸»ç¨‹åºå…¥å£
# ============================================================================

if __name__ == "__main__":
    # é…ç½®è·¯å¾„ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰
    DATA_DIR = "./data"        # æ•°æ®æ–‡ä»¶ç›®å½•
    OUTPUT_DIR = "./output"    # è¾“å‡ºç›®å½•
    
    # åˆ›å»ºé¢„æµ‹å™¨å¹¶è¿è¡Œ
    predictor = AmazonKnifeSalesPredictor(DATA_DIR, OUTPUT_DIR)
    predictor.run_full_pipeline()
