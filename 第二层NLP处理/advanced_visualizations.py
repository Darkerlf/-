"""
Amazon Reviews é«˜çº§å¯è§†åŒ–è„šæœ¬
åŸºäºNLPåˆ†æç»“æœç”Ÿæˆç²¾ç¾çš„å¯è§†åŒ–å›¾è¡¨

åŒ…å«:
1. è¯äº‘å›¾ (æ­£é¢/è´Ÿé¢/æ•´ä½“/ç—›ç‚¹)
2. æ–¹é¢æƒ…æ„Ÿé›·è¾¾å›¾
3. å“ç‰Œå¯¹æ¯”çƒ­åŠ›å›¾
4. å…³é”®è¯ç½‘ç»œå›¾
5. æƒ…æ„Ÿæµå‘å›¾
6. ä¸»é¢˜è¯äº‘
7. æ–¹é¢æ°”æ³¡å›¾
8. å“ç‰Œæƒ…æ„Ÿç®±å‹å›¾
9. ç—›ç‚¹æ¼æ–—å›¾
10. ç»¼åˆä»ªè¡¨ç›˜

è¿è¡Œ: python advanced_visualizations.py
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

# è®¾ç½®æ ·å¼
plt.rcParams['figure.figsize'] = (12, 8)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.size'] = 10
plt.rcParams['axes.unicode_minus'] = False
sns.set_style("whitegrid")
sns.set_palette("husl")

# åˆ›å»ºè¾“å‡ºç›®å½•
OUTPUT_DIR = 'advanced_visualizations'
Path(OUTPUT_DIR).mkdir(exist_ok=True)

print("=" * 80)
print("ğŸ¨ Amazon Kitchen Knife Reviews - é«˜çº§æ•°æ®å¯è§†åŒ–")
print("=" * 80)

# ==================== åŠ è½½æ•°æ® ====================
print("\nğŸ“‚ åŠ è½½æ•°æ®...")

absa_detailed = pd.read_csv('nlp_results/data/absa_detailed.csv')
absa_summary = pd.read_csv('nlp_results/data/absa_summary.csv')
bert_results = pd.read_csv('nlp_results/data/bert_sentiment_results.csv')
ner_brands = pd.read_csv('nlp_results/data/ner_brands.csv')
ner_materials = pd.read_csv('nlp_results/data/ner_materials.csv')
textrank_keywords = pd.read_csv('nlp_results/data/textrank_keywords.csv')
topic_modeling = pd.read_csv('nlp_results/data/topic_modeling.csv')

print(f"âœ… æ•°æ®åŠ è½½å®Œæˆ")
print(f"   - ABSAè¯¦ç»†æ•°æ®: {len(absa_detailed):,} æ¡")
print(f"   - BERTç»“æœ: {len(bert_results):,} æ¡")
print(f"   - å…³é”®è¯: {len(textrank_keywords)} ä¸ª")
print(f"   - å“ç‰Œ: {len(ner_brands)} ä¸ª")
print(f"   - æè´¨: {len(ner_materials)} ä¸ª")

# ==================== 1. è¯äº‘å›¾ (4åˆ1) ====================
print("\n[1/10] ğŸ¨ ç”Ÿæˆè¯äº‘å›¾...")

try:
    from wordcloud import WordCloud

    # å‡†å¤‡æ–‡æœ¬æ•°æ®
    positive_reviews = bert_results[bert_results['bert_label'] == 'POSITIVE']['review_text_clean']
    negative_reviews = bert_results[bert_results['bert_label'] == 'NEGATIVE']['review_text_clean']
    all_reviews = bert_results['review_text_clean']

    # åœç”¨è¯
    stopwords = set([
        'knife', 'knives', 'set', 'the', 'and', 'this', 'that', 'they', 'them', 'it', 'a', 'I', 'to', 'in', 'so', 'on',
        'one', 'all', 'out of','as','of','is',
        'these', 'those', 'have', 'has', 'had', 'with', 'from', 'been', 'were', 'was', 'look', 'only', 'you', 'my',
        'even', 'use', 'through', 'do', 'after', 'video guides', 'video',
        'are', 'but', 'for', 'not', 'just', 'very', 'really', 'like', 'get', 'got'
    ])

    # åˆ›å»º2x2å­å›¾
    fig, axes = plt.subplots(2, 2, figsize=(18, 14))
    fig.suptitle('Comprehensive Word Cloud Analysis', fontsize=20, fontweight='bold', y=0.98)

    # 1.1 æ•´ä½“è¯äº‘
    print("   - ç”Ÿæˆæ•´ä½“è¯äº‘...")
    wordcloud_all = WordCloud(
        width=800, height=600,
        background_color='white',
        stopwords=stopwords,
        colormap='viridis',
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10
    ).generate(' '.join(all_reviews.fillna('')))

    axes[0, 0].imshow(wordcloud_all, interpolation='bilinear')
    axes[0, 0].set_title('All Reviews - General Keywords', fontsize=14, fontweight='bold', pad=10)
    axes[0, 0].axis('off')

    # 1.2 æ­£é¢è¯äº‘
    print("   - ç”Ÿæˆæ­£é¢è¯äº‘...")
    wordcloud_pos = WordCloud(
        width=800, height=600,
        background_color='white',
        stopwords=stopwords,
        colormap='Greens',
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10
    ).generate(' '.join(positive_reviews.fillna('')))

    axes[0, 1].imshow(wordcloud_pos, interpolation='bilinear')
    axes[0, 1].set_title('Positive Reviews - What Users Love',
                         fontsize=14, fontweight='bold', color='darkgreen', pad=10)
    axes[0, 1].axis('off')

    # 1.3 è´Ÿé¢è¯äº‘
    print("   - ç”Ÿæˆè´Ÿé¢è¯äº‘...")
    wordcloud_neg = WordCloud(
        width=800, height=600,
        background_color='white',
        stopwords=stopwords,
        colormap='Reds',
        max_words=100,
        relative_scaling=0.5,
        min_font_size=10
    ).generate(' '.join(negative_reviews.fillna('')))

    axes[1, 0].imshow(wordcloud_neg, interpolation='bilinear')
    axes[1, 0].set_title('Negative Reviews - Pain Points',
                         fontsize=14, fontweight='bold', color='darkred', pad=10)
    axes[1, 0].axis('off')

    # 1.4 ç—›ç‚¹è¯äº‘ï¼ˆé»‘åº•ï¼‰
    print("   - ç”Ÿæˆç—›ç‚¹è¯äº‘...")
    pain_keywords = []
    for review in negative_reviews.fillna(''):
        words = review.lower().split()
        pain_words = [w for w in words if w in ['rust', 'rusted', 'rusting', 'dull', 'dulled',
                                                'broke', 'broken', 'crack', 'cracked', 'cracking', 'poor', 'cheap',
                                                'terrible', 'bad', 'disappointing', 'disappointed', 'waste',
                                                'horrible']]
        pain_keywords.extend(pain_words)

    if pain_keywords:
        from collections import Counter

        pain_freq = Counter(pain_keywords)

        wordcloud_pain = WordCloud(
            width=800, height=600,
            background_color='black',
            colormap='hot',
            max_words=50,
            relative_scaling=0.5,
            min_font_size=10
        ).generate_from_frequencies(pain_freq)

        axes[1, 1].imshow(wordcloud_pain, interpolation='bilinear')
        axes[1, 1].set_title('Critical Pain Points - What Went Wrong',
                             fontsize=14, fontweight='bold', color='darkred', pad=10)
        axes[1, 1].axis('off')

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/01_wordclouds_4in1.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   âœ… è¯äº‘å›¾å·²ä¿å­˜")

except ImportError:
    print("   âš ï¸  éœ€è¦å®‰è£…wordcloud: pip install wordcloud")
except Exception as e:
    print(f"   âŒ è¯äº‘å›¾ç”Ÿæˆå¤±è´¥: {e}")

# ==================== 2. æ–¹é¢æƒ…æ„Ÿé›·è¾¾å›¾ ====================
print("\n[2/10] ğŸ“Š ç”Ÿæˆæ–¹é¢æƒ…æ„Ÿé›·è¾¾å›¾...")

fig = plt.figure(figsize=(12, 10))
ax = fig.add_subplot(111, projection='polar')

# å‡†å¤‡æ•°æ®
aspects = absa_summary['aspect'].tolist()
sentiment_scores = absa_summary['avg_sentiment'].values
mention_rates = absa_summary['mention_rate'].values

# å½’ä¸€åŒ–æƒ…æ„Ÿå¾—åˆ†åˆ°0-1
sentiment_normalized = (sentiment_scores + 1) / 2  # ä»-1~1æ˜ å°„åˆ°0~1

# è§’åº¦
angles = np.linspace(0, 2 * np.pi, len(aspects), endpoint=False).tolist()
sentiment_plot = sentiment_normalized.tolist()
angles += angles[:1]
sentiment_plot += sentiment_plot[:1]

# ç»˜åˆ¶é›·è¾¾å›¾
ax.plot(angles, sentiment_plot, 'o-', linewidth=3, label='Sentiment Score',
        color='#2ecc71', markersize=8)
ax.fill(angles, sentiment_plot, alpha=0.25, color='#2ecc71')

# æ·»åŠ æåŠç‡ä½œä¸ºç‚¹çš„å¤§å°
mention_normalized = (mention_rates - mention_rates.min()) / (mention_rates.max() - mention_rates.min())
for i, (angle, score, mention) in enumerate(zip(angles[:-1], sentiment_plot[:-1], mention_normalized)):
    ax.scatter(angle, score, s=mention * 800, alpha=0.6, c='red', zorder=10, edgecolors='darkred', linewidth=2)

# è®¾ç½®æ ‡ç­¾
ax.set_xticks(angles[:-1])
ax.set_xticklabels(aspects, size=12, fontweight='bold')
ax.set_ylim(0, 1)
ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'], size=10)
ax.set_title('Aspect Sentiment Radar Chart\n(Red bubble size = Mention rate)',
             fontsize=16, fontweight='bold', pad=30)
ax.legend(loc='upper right', bbox_to_anchor=(1.35, 1.1), fontsize=11)
ax.grid(True, linewidth=1.5, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/02_aspect_radar_chart.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… é›·è¾¾å›¾å·²ä¿å­˜")

# ==================== 3. å“ç‰Œ-æƒ…æ„Ÿçƒ­åŠ›å›¾ ====================
print("\n[3/10] ğŸ”¥ ç”Ÿæˆå“ç‰Œå¯¹æ¯”çƒ­åŠ›å›¾...")

# ä¸ºæ¯ä¸ªå“ç‰Œè®¡ç®—æƒ…æ„Ÿç»Ÿè®¡
brand_sentiment_matrix = []
brands_list = ner_brands.head(8)['brand'].tolist()

for brand in brands_list:
    # æ‰¾åˆ°æåˆ°è¯¥å“ç‰Œçš„è¯„è®º
    brand_reviews = bert_results[
        bert_results['review_text_clean'].str.lower().str.contains(brand, na=False, regex=False)
    ]

    if len(brand_reviews) > 0:
        pos_rate = (brand_reviews['bert_label'] == 'POSITIVE').sum() / len(brand_reviews)
        avg_rating = brand_reviews['review_rating'].mean()
        count = len(brand_reviews)
        avg_score = brand_reviews['bert_score'].mean()

        brand_sentiment_matrix.append([pos_rate, avg_rating / 5, avg_score, count / max(1, len(brand_reviews))])
    else:
        brand_sentiment_matrix.append([0, 0, 0, 0])

brand_matrix = np.array(brand_sentiment_matrix).T

fig, ax = plt.subplots(figsize=(12, 6))
metrics = ['Positive Rate', 'Avg Rating\n(normalized)', 'BERT Score', 'Review Count\n(normalized)']

im = ax.imshow(brand_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)

ax.set_xticks(np.arange(len(brands_list)))
ax.set_yticks(np.arange(len(metrics)))
ax.set_xticklabels(brands_list, rotation=45, ha='right', fontsize=11)
ax.set_yticklabels(metrics, fontsize=11)

# æ·»åŠ æ•°å€¼
for i in range(len(metrics)):
    for j in range(len(brands_list)):
        text = ax.text(j, i, f'{brand_matrix[i, j]:.2f}',
                       ha="center", va="center", color="black", fontsize=10, fontweight='bold')

ax.set_title('Brand Comparison Heatmap', fontsize=16, fontweight='bold', pad=15)
cbar = plt.colorbar(im, ax=ax)
cbar.set_label('Score (0-1)', rotation=270, labelpad=20, fontsize=11)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/03_brand_heatmap.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… å“ç‰Œçƒ­åŠ›å›¾å·²ä¿å­˜")

# ==================== 4. å…³é”®è¯ç½‘ç»œå›¾ ====================
print("\n[4/10] ğŸ•¸ï¸  ç”Ÿæˆå…³é”®è¯ç½‘ç»œå›¾...")

try:
    import networkx as nx

    G = nx.Graph()

    # æ·»åŠ å…³é”®è¯èŠ‚ç‚¹
    top_keywords = textrank_keywords.head(20)

    for idx, row in top_keywords.iterrows():
        G.add_node(row['keyword'], weight=row['score'])

    # åŸºäºè¯åºæ·»åŠ è¾¹
    keywords_list = top_keywords['keyword'].tolist()
    for i in range(len(keywords_list)):
        for j in range(i + 1, min(i + 5, len(keywords_list))):
            G.add_edge(keywords_list[i], keywords_list[j], weight=1.0 / (j - i))

    # ç»˜åˆ¶
    fig, ax = plt.subplots(figsize=(16, 12))
    pos = nx.spring_layout(G, k=2.5, iterations=50, seed=42)

    # èŠ‚ç‚¹å¤§å°
    node_sizes = [G.nodes[node]['weight'] * 50000 for node in G.nodes()]

    # è¾¹æƒé‡
    edges = G.edges()
    weights = [G[u][v]['weight'] for u, v in edges]

    # ç»˜åˆ¶
    nx.draw_networkx_nodes(G, pos, node_size=node_sizes,
                           node_color='lightblue', alpha=0.7, ax=ax,
                           edgecolors='darkblue', linewidths=2)
    nx.draw_networkx_edges(G, pos, alpha=0.3, width=weights, ax=ax, edge_color='gray')
    nx.draw_networkx_labels(G, pos, font_size=11, font_weight='bold', ax=ax)

    ax.set_title('Keyword Network Graph\n(Node size = Importance)', fontsize=16, fontweight='bold')
    ax.axis('off')
    ax.margins(0.1)

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/04_keyword_network.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   âœ… ç½‘ç»œå›¾å·²ä¿å­˜")

except ImportError:
    print("   âš ï¸  éœ€è¦å®‰è£…networkx: pip install networkx")
except Exception as e:
    print(f"   âŒ ç½‘ç»œå›¾ç”Ÿæˆå¤±è´¥: {e}")

# ==================== 5. æƒ…æ„Ÿ-è¯„åˆ†æµå‘å›¾ ====================
print("\n[5/10] ğŸ“ˆ ç”Ÿæˆæƒ…æ„Ÿæµå‘å›¾...")

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

# 5.1 å †å æŸ±çŠ¶å›¾
rating_sentiment = bert_results.groupby(['review_rating', 'bert_label']).size().unstack(fill_value=0)

ratings = sorted(bert_results['review_rating'].unique())
x = np.arange(len(ratings))
width = 0.6

if 'POSITIVE' in rating_sentiment.columns:
    ax1.bar(x, rating_sentiment['POSITIVE'], width, label='Positive',
            color='#2ecc71', alpha=0.8, edgecolor='black', linewidth=1.5)
if 'NEGATIVE' in rating_sentiment.columns:
    bottom = rating_sentiment['POSITIVE'] if 'POSITIVE' in rating_sentiment.columns else 0
    ax1.bar(x, rating_sentiment['NEGATIVE'], width, bottom=bottom,
            label='Negative', color='#e74c3c', alpha=0.8, edgecolor='black', linewidth=1.5)

ax1.set_xlabel('Star Rating', fontsize=12, fontweight='bold')
ax1.set_ylabel('Review Count', fontsize=12, fontweight='bold')
ax1.set_title('Sentiment Distribution by Rating', fontsize=14, fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels([f'{int(r)} â˜…' for r in ratings], fontsize=11)
ax1.legend(fontsize=11)
ax1.grid(axis='y', alpha=0.3)

# 5.2 æ¯”ä¾‹é¢ç§¯å›¾
pos_counts = []
neg_counts = []
for rating in ratings:
    rating_data = bert_results[bert_results['review_rating'] == rating]
    total = len(rating_data)
    if total > 0:
        pos_pct = (rating_data['bert_label'] == 'POSITIVE').sum() / total * 100
        neg_pct = (rating_data['bert_label'] == 'NEGATIVE').sum() / total * 100
    else:
        pos_pct = neg_pct = 0
    pos_counts.append(pos_pct)
    neg_counts.append(neg_pct)

ax2.fill_between(ratings, pos_counts, alpha=0.5, color='green', label='Positive %')
ax2.fill_between(ratings, neg_counts, alpha=0.5, color='red', label='Negative %')
ax2.plot(ratings, pos_counts, 'o-', color='darkgreen', linewidth=2, markersize=8)
ax2.plot(ratings, neg_counts, 'o-', color='darkred', linewidth=2, markersize=8)

ax2.set_xlabel('Star Rating', fontsize=12, fontweight='bold')
ax2.set_ylabel('Percentage (%)', fontsize=12, fontweight='bold')
ax2.set_title('Sentiment Percentage by Rating', fontsize=14, fontweight='bold')
ax2.legend(fontsize=11)
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/05_sentiment_flow.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… æµå‘å›¾å·²ä¿å­˜")

# ==================== 6. ä¸»é¢˜è¯äº‘ ====================
print("\n[6/10] ğŸ¯ ç”Ÿæˆä¸»é¢˜è¯äº‘...")

try:
    from wordcloud import WordCloud

    lda_topics = topic_modeling[topic_modeling['method'] == 'LDA']

    if len(lda_topics) > 0:
        n_topics = min(len(lda_topics), 6)
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()

        for i, (idx, row) in enumerate(lda_topics.head(6).iterrows()):
            topic_words = row['top_words']

            wordcloud = WordCloud(
                width=600, height=400,
                background_color='white',
                colormap=['tab10', 'Set3', 'Pastel1', 'Dark2', 'Set2', 'Accent'][i % 6],
                max_words=40,
                relative_scaling=0.5
            ).generate(topic_words)

            axes[i].imshow(wordcloud, interpolation='bilinear')
            axes[i].set_title(f'Topic {i + 1}: {topic_words.split(",")[0]}...',
                              fontsize=12, fontweight='bold')
            axes[i].axis('off')

        # éšè—å¤šä½™å­å›¾
        for i in range(len(lda_topics), 6):
            axes[i].axis('off')

        plt.suptitle('LDA Topic Modeling - Word Clouds', fontsize=16, fontweight='bold')
        plt.tight_layout()
        plt.savefig(f'{OUTPUT_DIR}/06_topic_wordclouds.png', dpi=300, bbox_inches='tight')
        plt.close()
        print("   âœ… ä¸»é¢˜è¯äº‘å·²ä¿å­˜")

except Exception as e:
    print(f"   âŒ ä¸»é¢˜è¯äº‘ç”Ÿæˆå¤±è´¥: {e}")

# ==================== 7. æ–¹é¢æ°”æ³¡å›¾ ====================
print("\n[7/10] ğŸ’­ ç”Ÿæˆæ–¹é¢æ°”æ³¡å›¾...")

fig, ax = plt.subplots(figsize=(14, 8))

aspects = absa_summary['aspect'].tolist()
x_pos = range(len(aspects))
y_sentiment = absa_summary['avg_sentiment'].values
sizes = absa_summary['mention_count'].values
colors = ['#2ecc71' if s > 0.1 else '#e74c3c' if s < -0.1 else '#95a5a6' for s in y_sentiment]

# ç»˜åˆ¶æ°”æ³¡
scatter = ax.scatter(x_pos, y_sentiment, s=sizes * 3, c=colors, alpha=0.6,
                     edgecolors='black', linewidth=2, zorder=10)

# æ·»åŠ æ ‡ç­¾
for i, (aspect, sent) in enumerate(zip(aspects, y_sentiment)):
    ax.text(i, sent + 0.05, aspect, ha='center', va='bottom',
            fontsize=11, fontweight='bold')
    ax.text(i, sent - 0.05, f'({int(sizes[i])})', ha='center', va='top',
            fontsize=9, style='italic', alpha=0.7)

# æ·»åŠ é›¶çº¿
ax.axhline(y=0, color='gray', linestyle='--', linewidth=2, alpha=0.5, label='Neutral line')

ax.set_xlabel('Product Aspects', fontsize=13, fontweight='bold')
ax.set_ylabel('Average Sentiment Score', fontsize=13, fontweight='bold')
ax.set_title('Aspect Sentiment Bubble Chart\n(Bubble size = Mention count)',
             fontsize=16, fontweight='bold', pad=15)
ax.set_xticks(x_pos)
ax.set_xticklabels(aspects, rotation=45, ha='right', fontsize=11)
ax.grid(True, alpha=0.3, linestyle=':')
ax.legend(fontsize=10)

# æ·»åŠ é¢œè‰²è¯´æ˜
from matplotlib.patches import Patch

legend_elements = [
    Patch(facecolor='#2ecc71', edgecolor='black', label='Positive (>0.1)'),
    Patch(facecolor='#95a5a6', edgecolor='black', label='Neutral'),
    Patch(facecolor='#e74c3c', edgecolor='black', label='Negative (<-0.1)')
]
ax.legend(handles=legend_elements, loc='upper left', fontsize=10)

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/07_aspect_bubble_chart.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… æ°”æ³¡å›¾å·²ä¿å­˜")

# ==================== 8. å“ç‰Œæƒ…æ„Ÿç®±å‹å›¾ ====================
print("\n[8/10] ğŸ“¦ ç”Ÿæˆå“ç‰Œå¯¹æ¯”ç®±å‹å›¾...")

brand_sentiment_data = []

for brand in ner_brands.head(6)['brand']:
    brand_reviews = bert_results[
        bert_results['review_text_clean'].str.lower().str.contains(brand, na=False, regex=False)
    ]

    if len(brand_reviews) > 0:
        for _, row in brand_reviews.iterrows():
            score = row['bert_score'] if row['bert_label'] == 'POSITIVE' else -row['bert_score']
            brand_sentiment_data.append({
                'brand': brand.capitalize(),
                'sentiment_score': score
            })

if brand_sentiment_data:
    brand_df = pd.DataFrame(brand_sentiment_data)

    fig, ax = plt.subplots(figsize=(14, 8))

    brands = brand_df['brand'].unique()
    data_to_plot = [brand_df[brand_df['brand'] == b]['sentiment_score'].values for b in brands]

    bp = ax.boxplot(data_to_plot, labels=brands, patch_artist=True,
                    boxprops=dict(facecolor='lightblue', alpha=0.7, linewidth=2),
                    medianprops=dict(color='red', linewidth=3),
                    whiskerprops=dict(linewidth=2),
                    capprops=dict(linewidth=2),
                    flierprops=dict(marker='o', markerfacecolor='red', markersize=8, alpha=0.5))

    ax.axhline(y=0, color='black', linestyle='--', linewidth=2, alpha=0.5, label='Neutral')
    ax.set_xlabel('Brand', fontsize=13, fontweight='bold')
    ax.set_ylabel('Sentiment Score', fontsize=13, fontweight='bold')
    ax.set_title('Brand Sentiment Distribution (Box Plot)', fontsize=16, fontweight='bold', pad=15)
    ax.grid(axis='y', alpha=0.3)
    ax.legend(fontsize=10)
    plt.xticks(rotation=45, ha='right', fontsize=11)

    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/08_brand_boxplot.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("   âœ… ç®±å‹å›¾å·²ä¿å­˜")
else:
    print("   âš ï¸  å“ç‰Œæ•°æ®ä¸è¶³ï¼Œè·³è¿‡")

# ==================== 9. ç—›ç‚¹æ¼æ–—å›¾ ====================
print("\n[9/10] ğŸ”» ç”Ÿæˆç—›ç‚¹æ¼æ–—å›¾...")

negative_reviews = bert_results[bert_results['bert_label'] == 'NEGATIVE']

pain_points = {
    'Rust/Corrosion': 0,
    'Dull Blade': 0,
    'Handle Issues': 0,
    'Poor Quality': 0,
    'Broke/Cracked': 0,
    'Expensive': 0
}

for review in negative_reviews['review_text_clean'].fillna(''):
    review_lower = review.lower()
    if any(word in review_lower for word in ['rust', 'rusted', 'rusting', 'corrosion']):
        pain_points['Rust/Corrosion'] += 1
    if 'dull' in review_lower:
        pain_points['Dull Blade'] += 1
    if 'handle' in review_lower and any(word in review_lower for word in ['crack', 'split', 'break', 'loose']):
        pain_points['Handle Issues'] += 1
    if any(word in review_lower for word in ['poor', 'cheap', 'bad', 'terrible']):
        pain_points['Poor Quality'] += 1
    if any(word in review_lower for word in ['broke', 'crack', 'break', 'chip']):
        pain_points['Broke/Cracked'] += 1
    if any(word in review_lower for word in ['expensive', 'overpriced', 'waste money']):
        pain_points['Expensive'] += 1

pain_points_sorted = sorted(pain_points.items(), key=lambda x: x[1], reverse=True)

fig, ax = plt.subplots(figsize=(12, 10))

y_pos = range(len(pain_points_sorted))
counts = [p[1] for p in pain_points_sorted]
labels = [p[0] for p in pain_points_sorted]

colors = plt.cm.Reds(np.linspace(0.4, 0.9, len(pain_points_sorted)))

for i, (label, count) in enumerate(pain_points_sorted):
    width = count / max(counts) * 10
    bar = ax.barh(i, width, height=0.7, color=colors[i], alpha=0.8,
                  edgecolor='darkred', linewidth=2)

    ax.text(width + 0.3, i, f'{count} mentions\n({count / len(negative_reviews) * 100:.1f}%)',
            va='center', fontsize=11, fontweight='bold')

ax.set_yticks(y_pos)
ax.set_yticklabels(labels, fontsize=13, fontweight='bold')
ax.set_xlabel('Relative Frequency', fontsize=13, fontweight='bold')
ax.set_title('Pain Points Analysis (Funnel Chart)\nBased on Negative Reviews',
             fontsize=16, fontweight='bold', pad=15)
ax.invert_yaxis()
ax.set_xlim(0, 12)

# æ·»åŠ è¯´æ˜
ax.text(11, len(pain_points_sorted) - 0.5,
        f'Total Negative Reviews: {len(negative_reviews)}',
        fontsize=10, style='italic', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

plt.tight_layout()
plt.savefig(f'{OUTPUT_DIR}/09_pain_points_funnel.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… ç—›ç‚¹æ¼æ–—å›¾å·²ä¿å­˜")

# ==================== 10. ç»¼åˆä»ªè¡¨ç›˜ ====================
print("\n[10/10] ğŸ“Š ç”Ÿæˆç»¼åˆä»ªè¡¨ç›˜...")

fig = plt.figure(figsize=(20, 14))
gs = fig.add_gridspec(4, 4, hspace=0.4, wspace=0.4)

# 10.1 æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
ax1 = fig.add_subplot(gs[0, 0])
sentiment_counts = bert_results['bert_label'].value_counts()
colors_pie = ['#2ecc71', '#e74c3c']
wedges, texts, autotexts = ax1.pie(sentiment_counts.values, labels=sentiment_counts.index,
                                   autopct='%1.1f%%', colors=colors_pie, startangle=90,
                                   textprops={'fontsize': 11, 'fontweight': 'bold'})
ax1.set_title('Overall Sentiment', fontweight='bold', fontsize=12, pad=10)

# 10.2 è¯„åˆ†åˆ†å¸ƒ
ax2 = fig.add_subplot(gs[0, 1])
rating_dist = bert_results['review_rating'].value_counts().sort_index()
bars = ax2.bar(rating_dist.index, rating_dist.values, color='steelblue', alpha=0.7, edgecolor='black')
for bar in bars:
    height = bar.get_height()
    ax2.text(bar.get_x() + bar.get_width() / 2., height,
             f'{int(height)}', ha='center', va='bottom', fontsize=9, fontweight='bold')
ax2.set_xlabel('Star Rating', fontweight='bold')
ax2.set_ylabel('Count', fontweight='bold')
ax2.set_title('Rating Distribution', fontweight='bold', fontsize=12, pad=10)
ax2.grid(axis='y', alpha=0.3)

# 10.3 Topå“ç‰Œ
ax3 = fig.add_subplot(gs[0, 2:])
top_brands = ner_brands.head(8)
bars = ax3.barh(top_brands['brand'], top_brands['count'], color='coral', alpha=0.7, edgecolor='black')
for bar in bars:
    width = bar.get_width()
    ax3.text(width, bar.get_y() + bar.get_height() / 2.,
             f' {int(width)}', ha='left', va='center', fontsize=10, fontweight='bold')
ax3.set_xlabel('Mention Count', fontweight='bold')
ax3.set_title('Top Brands Mentioned', fontweight='bold', fontsize=12, pad=10)
ax3.invert_yaxis()

# 10.4 æ–¹é¢æƒ…æ„Ÿ
ax4 = fig.add_subplot(gs[1, :])
aspects = absa_summary['aspect'].tolist()
sentiments = absa_summary['avg_sentiment'].values
colors_aspect = ['#2ecc71' if s > 0.1 else '#e74c3c' if s < -0.1 else '#95a5a6' for s in sentiments]
bars = ax4.barh(aspects, sentiments, color=colors_aspect, alpha=0.7, edgecolor='black', linewidth=1.5)
for i, (bar, sent) in enumerate(zip(bars, sentiments)):
    width = bar.get_width()
    ax4.text(width + (0.02 if width > 0 else -0.02), bar.get_y() + bar.get_height() / 2.,
             f'{sent:.2f}', ha='left' if width > 0 else 'right', va='center',
             fontsize=10, fontweight='bold')
ax4.axvline(x=0, color='black', linewidth=2)
ax4.set_xlabel('Sentiment Score', fontweight='bold', fontsize=11)
ax4.set_title('ABSA: Aspect Sentiment Scores', fontweight='bold', fontsize=13, pad=10)
ax4.grid(axis='x', alpha=0.3)

# 10.5 å…³é”®è¯Top 12
ax5 = fig.add_subplot(gs[2, :2])
top_kw = textrank_keywords.head(12)
bars = ax5.barh(range(len(top_kw)), top_kw.iloc[:, 1].values, color='skyblue', alpha=0.7, edgecolor='black')
ax5.set_yticks(range(len(top_kw)))
ax5.set_yticklabels(top_kw.iloc[:, 0].values, fontsize=10)
ax5.invert_yaxis()
ax5.set_xlabel('TextRank Score', fontweight='bold')
ax5.set_title('Top Keywords (TextRank)', fontweight='bold', fontsize=12, pad=10)

# 10.6 æè´¨åˆ†å¸ƒ
ax6 = fig.add_subplot(gs[2, 2:])
top_materials = ner_materials.head(6)
wedges, texts, autotexts = ax6.pie(top_materials['count'].values,
                                   labels=[m.capitalize() for m in top_materials['material'].values],
                                   autopct='%1.1f%%', startangle=90,
                                   textprops={'fontsize': 9, 'fontweight': 'bold'})
ax6.set_title('Material Mentions', fontweight='bold', fontsize=12, pad=10)

# 10.7 è¯„è®ºé•¿åº¦åˆ†å¸ƒ
ax7 = fig.add_subplot(gs[3, :2])
text_lens = bert_results[bert_results['review_text_clean'].notna()]['review_text_clean'].str.len()
ax7.hist(text_lens, bins=50, color='lightgreen', alpha=0.7, edgecolor='black')
median_len = text_lens.median()
ax7.axvline(median_len, color='red', linestyle='--', linewidth=2,
            label=f'Median: {int(median_len)} chars')
ax7.set_xlabel('Review Length (characters)', fontweight='bold')
ax7.set_ylabel('Frequency', fontweight='bold')
ax7.set_title('Review Length Distribution', fontweight='bold', fontsize=12, pad=10)
ax7.legend(fontsize=10)
ax7.grid(axis='y', alpha=0.3)

# 10.8 å…³é”®æŒ‡æ ‡å¡
ax8 = fig.add_subplot(gs[3, 2:])
ax8.axis('off')

metrics_text = f"""
KEY METRICS SUMMARY
{'=' * 40}

Total Reviews: {len(bert_results):,}
Positive Rate: {(bert_results['bert_label'] == 'POSITIVE').sum() / len(bert_results) * 100:.1f}%
Negative Rate: {(bert_results['bert_label'] == 'NEGATIVE').sum() / len(bert_results) * 100:.1f}%

Average Rating: {bert_results['review_rating'].mean():.2f} / 5.0
Median Review Length: {int(median_len)} characters

Top Aspect: {aspects[0]} ({absa_summary.iloc[0]['mention_rate']:.1f}% mention)
Biggest Pain Point: Rust ({pain_points['Rust/Corrosion']} mentions)

Most Mentioned Brand: {ner_brands.iloc[0]['brand'].capitalize()}
Most Mentioned Material: {ner_materials.iloc[0]['material'].capitalize()}
"""

ax8.text(0.1, 0.5, metrics_text, fontsize=11, fontfamily='monospace',
         verticalalignment='center',
         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5, pad=1))

plt.suptitle('Amazon Kitchen Knife Reviews - Comprehensive Analytics Dashboard',
             fontsize=18, fontweight='bold', y=0.99)

plt.savefig(f'{OUTPUT_DIR}/10_comprehensive_dashboard.png', dpi=300, bbox_inches='tight')
plt.close()
print("   âœ… ç»¼åˆä»ªè¡¨ç›˜å·²ä¿å­˜")

# ==================== ç”Ÿæˆå›¾è¡¨è¯´æ˜æ–‡æ¡£ ====================
summary_md = f"""# ğŸ“Š é«˜çº§å¯è§†åŒ–å›¾è¡¨è¯´æ˜æ–‡æ¡£

ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}

---

## ğŸ“ å›¾è¡¨æ¸…å•

### 1ï¸âƒ£ ç»¼åˆè¯äº‘å›¾ (01_wordclouds_4in1.png)
**å†…å®¹**: 4åˆ1è¯äº‘åˆ†æ
- **å·¦ä¸Š**: æ•´ä½“è¯äº‘ - æ‰€æœ‰è¯„è®ºçš„å…³é”®è¯
- **å³ä¸Š**: æ­£é¢è¯äº‘ - ç”¨æˆ·å–œæ¬¢ä»€ä¹ˆï¼ˆç»¿è‰²ä¸»é¢˜ï¼‰
- **å·¦ä¸‹**: è´Ÿé¢è¯äº‘ - ç”¨æˆ·ä¸æ»¡æ„ä»€ä¹ˆï¼ˆçº¢è‰²ä¸»é¢˜ï¼‰
- **å³ä¸‹**: ç—›ç‚¹è¯äº‘ - æ ¸å¿ƒé—®é¢˜è¯ï¼ˆé»‘åº•çƒ­åŠ›å›¾ï¼‰

**å±•ç¤ºå»ºè®®**: æ”¾åœ¨PPTç¬¬2-3é¡µï¼Œå¿«é€Ÿå±•ç¤ºç”¨æˆ·å£°éŸ³
**æ ¸å¿ƒæ´å¯Ÿ**: 
- æ­£é¢è¯: sharp, quality, great, love
- è´Ÿé¢è¯: rust, dull, broke, cheap, disappointing

---

### 2ï¸âƒ£ æ–¹é¢æƒ…æ„Ÿé›·è¾¾å›¾ (02_aspect_radar_chart.png)
**å†…å®¹**: 8ä¸ªäº§å“æ–¹é¢çš„æƒ…æ„Ÿå¾—åˆ†é›·è¾¾å›¾
- ç»¿çº¿: æƒ…æ„Ÿå¾—åˆ†ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
- çº¢è‰²æ°”æ³¡: æåŠç‡ï¼ˆè¶Šå¤§è¯´æ˜ç”¨æˆ·è¶Šå…³æ³¨ï¼‰

**å±•ç¤ºå»ºè®®**: PPTæ ¸å¿ƒé¡µï¼Œå±•ç¤ºäº§å“å¼ºå¼±é¡¹
**æ ¸å¿ƒæ´å¯Ÿ**:
- âœ… ä¼˜åŠ¿: Sharpness, Quality, Appearance
- âš ï¸ ç—›ç‚¹: Rust (è´Ÿé¢æƒ…æ„Ÿ)

---

### 3ï¸âƒ£ å“ç‰Œå¯¹æ¯”çƒ­åŠ›å›¾ (03_brand_heatmap.png)
**å†…å®¹**: Top 8å“ç‰Œçš„4ä¸ªç»´åº¦å¯¹æ¯”
- æ­£é¢è¯„ä»·ç‡
- å¹³å‡è¯„åˆ†
- BERTç½®ä¿¡åº¦
- è¯„è®ºæ•°é‡

**å±•ç¤ºå»ºè®®**: ç«å“åˆ†æç¯èŠ‚
**æ ¸å¿ƒæ´å¯Ÿ**: 
- Cuisinart: æåŠæœ€å¤šä½†è¯„åˆ†ä¸€èˆ¬
- æœºä¼š: é¿å¼€å¤´éƒ¨å“ç‰Œç›´æ¥ç«äº‰

---

### 4ï¸âƒ£ å…³é”®è¯ç½‘ç»œå›¾ (04_keyword_network.png)
**å†…å®¹**: Top 20å…³é”®è¯çš„å…³è”ç½‘ç»œ
- èŠ‚ç‚¹å¤§å° = è¯è¯­é‡è¦æ€§
- è¿çº¿ = è¯è¯­ä¹‹é—´çš„å…³è”

**å±•ç¤ºå»ºè®®**: æŠ€æœ¯å±•ç¤ºç¯èŠ‚
**æ ¸å¿ƒæ´å¯Ÿ**: è¯†åˆ«å…³é”®è¯ç°‡å’Œä¸»é¢˜

---

### 5ï¸âƒ£ æƒ…æ„Ÿæµå‘å›¾ (05_sentiment_flow.png)
**å†…å®¹**: è¯„åˆ†-æƒ…æ„ŸåŒç»´åº¦åˆ†æ
- å·¦å›¾: å †å æŸ±çŠ¶å›¾ï¼ˆç»å¯¹æ•°é‡ï¼‰
- å³å›¾: ç™¾åˆ†æ¯”é¢ç§¯å›¾ï¼ˆç›¸å¯¹æ¯”ä¾‹ï¼‰

**å±•ç¤ºå»ºè®®**: éªŒè¯BERTå‡†ç¡®æ€§
**æ ¸å¿ƒæ´å¯Ÿ**: 
- 5æ˜Ÿè¯„è®ºå‡ ä¹å…¨æ˜¯æ­£é¢æƒ…æ„Ÿ
- 1-2æ˜Ÿè¯„è®ºä»¥è´Ÿé¢ä¸ºä¸»
- BERTæ¨¡å‹å‡†ç¡®åº¦é«˜ âœ…

---

### 6ï¸âƒ£ ä¸»é¢˜è¯äº‘å›¾ (06_topic_wordclouds.png)
**å†…å®¹**: LDAä¸»é¢˜å»ºæ¨¡çš„6ä¸ªä¸»é¢˜è¯äº‘
- æ¯ä¸ªä¸»é¢˜ç”¨ä¸åŒé¢œè‰²
- å±•ç¤ºä¸»é¢˜çš„æ ¸å¿ƒè¯æ±‡

**å±•ç¤ºå»ºè®®**: ç”¨æˆ·è®¨è®ºè¯é¢˜åˆ†æ
**æ ¸å¿ƒæ´å¯Ÿ**: 
- Topic 1: Performance & Sharpness
- Topic 2: Quality & Durability
- Topic 3: Value & Price
- (ç­‰)

---

### 7ï¸âƒ£ æ–¹é¢æ°”æ³¡å›¾ (07_aspect_bubble_chart.png)
**å†…å®¹**: æ–¹é¢æåŠæ¬¡æ•°ä¸æƒ…æ„Ÿå¾—åˆ†çš„æ°”æ³¡å›¾
- Xè½´: äº§å“æ–¹é¢
- Yè½´: å¹³å‡æƒ…æ„Ÿå¾—åˆ†
- æ°”æ³¡å¤§å°: æåŠæ¬¡æ•°
- é¢œè‰²: ç»¿(æ­£é¢) çº¢(è´Ÿé¢) ç°(ä¸­æ€§)

**å±•ç¤ºå»ºè®®**: å¿«é€Ÿè¯†åˆ«æ ¸å¿ƒé—®é¢˜
**æ ¸å¿ƒæ´å¯Ÿ**:
- Sharpness: é«˜æåŠ+é«˜æƒ…æ„Ÿ = æ ¸å¿ƒå–ç‚¹ âœ…
- Rust: ä¸­æåŠ+è´Ÿæƒ…æ„Ÿ = æ ¸å¿ƒç—›ç‚¹ âš ï¸

---

### 8ï¸âƒ£ å“ç‰Œæƒ…æ„Ÿç®±å‹å›¾ (08_brand_boxplot.png)
**å†…å®¹**: Top 6å“ç‰Œçš„æƒ…æ„Ÿå¾—åˆ†åˆ†å¸ƒ
- ç®±ä½“: 25%-75%åˆ†ä½æ•°
- çº¢çº¿: ä¸­ä½æ•°
- è§¦é¡»: æœ€å¤§/æœ€å°å€¼
- åœ†ç‚¹: å¼‚å¸¸å€¼

**å±•ç¤ºå»ºè®®**: å“ç‰Œæ»¡æ„åº¦å¯¹æ¯”
**æ ¸å¿ƒæ´å¯Ÿ**: 
- ç®±ä½“è¶Šé«˜ = ç”¨æˆ·è¯„ä»·è¶Šå¥½
- ç®±ä½“è¶Šçª„ = è¯„ä»·è¶Šä¸€è‡´

---

### 9ï¸âƒ£ ç—›ç‚¹æ¼æ–—å›¾ (09_pain_points_funnel.png)
**å†…å®¹**: è´Ÿé¢è¯„è®ºä¸­çš„6å¤§ç—›ç‚¹æ’å
1. Rust/Corrosion - ç”Ÿé”ˆ/è…èš€
2. Dull Blade - åˆ€åˆƒå˜é’
3. Handle Issues - æ‰‹æŸ„é—®é¢˜
4. Poor Quality - è´¨é‡å·®
5. Broke/Cracked - æ–­è£‚/ç ´æŸ
6. Expensive - ä»·æ ¼è´µ

**å±•ç¤ºå»ºè®®**: äº§å“æ”¹è¿›ä¼˜å…ˆçº§
**æ ¸å¿ƒæ´å¯Ÿ**:
- âš ï¸ Rustæ˜¯æœ€å¤§ç—›ç‚¹ï¼ˆå è´Ÿé¢è¯„è®ºçš„XX%ï¼‰
- æ”¹è¿›å»ºè®®: å‡çº§é˜²é”ˆæŠ€æœ¯ + è´¨ä¿æ‰¿è¯º

---

### ğŸ”Ÿ ç»¼åˆä»ªè¡¨ç›˜ (10_comprehensive_dashboard.png)
**å†…å®¹**: 8åˆ1æ•°æ®çœ‹æ¿
- æƒ…æ„Ÿåˆ†å¸ƒé¥¼å›¾
- è¯„åˆ†åˆ†å¸ƒæŸ±çŠ¶å›¾
- Topå“ç‰Œæ’è¡Œ
- æ–¹é¢æƒ…æ„Ÿæ¡å½¢å›¾
- å…³é”®è¯æ’å
- æè´¨åˆ†å¸ƒ
- è¯„è®ºé•¿åº¦åˆ†å¸ƒ
- å…³é”®æŒ‡æ ‡æ‘˜è¦

**å±•ç¤ºå»ºè®®**: PPTé¦–é¡µæˆ–æ€»ç»“é¡µ
**æ ¸å¿ƒæ´å¯Ÿ**: ä¸€é¡µçº¸çœ‹æ‡‚æ‰€æœ‰æ ¸å¿ƒæ•°æ®

---

## ğŸ¯ PPTå±•ç¤ºå»ºè®®

### ç»“æ„1: é—®é¢˜å¯¼å‘å‹
```
ç¬¬1é¡µ: å°é¢
ç¬¬2é¡µ: ç»¼åˆä»ªè¡¨ç›˜ï¼ˆå…¨æ™¯ï¼‰
ç¬¬3é¡µ: è¯äº‘å›¾ï¼ˆç”¨æˆ·å£°éŸ³ï¼‰
ç¬¬4é¡µ: ABSAé›·è¾¾å›¾ï¼ˆäº§å“åˆ†æï¼‰
ç¬¬5é¡µ: ç—›ç‚¹æ¼æ–—å›¾ï¼ˆæ ¸å¿ƒé—®é¢˜ï¼‰
ç¬¬6é¡µ: è§£å†³æ–¹æ¡ˆï¼ˆåŸºäºæ•°æ®ï¼‰
```

### ç»“æ„2: æŠ€æœ¯å±•ç¤ºå‹
```
ç¬¬1é¡µ: å°é¢
ç¬¬2é¡µ: æŠ€æœ¯è·¯çº¿ï¼ˆ5é¡¹NLPï¼‰
ç¬¬3é¡µ: BERTç»“æœï¼ˆæƒ…æ„Ÿæµå‘å›¾ï¼‰
ç¬¬4é¡µ: ABSAç»“æœï¼ˆé›·è¾¾å›¾+æ°”æ³¡å›¾ï¼‰
ç¬¬5é¡µ: TextRankç»“æœï¼ˆç½‘ç»œå›¾+è¯äº‘ï¼‰
ç¬¬6é¡µ: ä¸»é¢˜å»ºæ¨¡ï¼ˆä¸»é¢˜è¯äº‘ï¼‰
ç¬¬7é¡µ: å•†ä¸šæ´å¯Ÿ
```

---

## ğŸ’¡ ä½¿ç”¨æŠ€å·§

### é…è‰²æ–¹æ¡ˆ
- âœ… æ­£é¢: #2ecc71 (ç»¿è‰²)
- âŒ è´Ÿé¢: #e74c3c (çº¢è‰²)
- ğŸ˜ ä¸­æ€§: #95a5a6 (ç°è‰²)
- ç»Ÿä¸€é…è‰²æå‡ä¸“ä¸šåº¦

### æ•°æ®æ ‡æ³¨
- æ¯å¼ å›¾éƒ½æ·»åŠ äº†å…·ä½“æ•°å€¼
- ä¾¿äºè§‚ä¼—ç†è§£å’Œè®°å¿†

### é«˜æ¸…è¾“å‡º
- æ‰€æœ‰å›¾è¡¨å‡ä¸º300 DPI
- æ‰“å°å’ŒæŠ•å½±éƒ½æ¸…æ™°

---

## ğŸ“ˆ æ ¸å¿ƒæ•°æ®æ‘˜è¦

åŸºäºè¿™äº›å›¾è¡¨ï¼Œä½ å¯ä»¥å¾—å‡ºï¼š

1. **ç”¨æˆ·æ»¡æ„åº¦**: {(bert_results['bert_label'] == 'POSITIVE').sum() / len(bert_results) * 100:.1f}% æ­£é¢è¯„ä»·
2. **æœ€å¤§å–ç‚¹**: Sharpnessï¼ˆé”‹åˆ©åº¦ï¼‰- {absa_summary.iloc[0]['mention_rate']:.1f}%æåŠç‡
3. **æœ€å¤§ç—›ç‚¹**: Rustï¼ˆé˜²é”ˆï¼‰- è´Ÿé¢æƒ…æ„Ÿ
4. **ä¸»è¦ç«å“**: {ner_brands.iloc[0]['brand'].capitalize()}
5. **å…³æ³¨æè´¨**: {ner_materials.iloc[0]['material'].capitalize()}

---

**ğŸ‰ æ‰€æœ‰å›¾è¡¨å·²ç”Ÿæˆï¼Œå¯ç›´æ¥ç”¨äºæ¯”èµ›å±•ç¤ºï¼**
"""

with open(f'{OUTPUT_DIR}/å›¾è¡¨è¯´æ˜æ–‡æ¡£.md', 'w', encoding='utf-8') as f:
    f.write(summary_md)

# ==================== å®Œæˆ ====================
print("\n" + "=" * 80)
print("ğŸ‰ æ‰€æœ‰å¯è§†åŒ–ç”Ÿæˆå®Œæˆ!")
print("=" * 80)

print(f"\nğŸ“ è¾“å‡ºç›®å½•: {OUTPUT_DIR}/")
print("\nğŸ“Š ç”Ÿæˆçš„å›¾è¡¨:")
print("   1. 01_wordclouds_4in1.png - ç»¼åˆè¯äº‘å›¾ï¼ˆ4åˆ1ï¼‰")
print("   2. 02_aspect_radar_chart.png - æ–¹é¢æƒ…æ„Ÿé›·è¾¾å›¾")
print("   3. 03_brand_heatmap.png - å“ç‰Œå¯¹æ¯”çƒ­åŠ›å›¾")
print("   4. 04_keyword_network.png - å…³é”®è¯ç½‘ç»œå›¾")
print("   5. 05_sentiment_flow.png - æƒ…æ„Ÿæµå‘å›¾")
print("   6. 06_topic_wordclouds.png - ä¸»é¢˜è¯äº‘å›¾")
print("   7. 07_aspect_bubble_chart.png - æ–¹é¢æ°”æ³¡å›¾")
print("   8. 08_brand_boxplot.png - å“ç‰Œæƒ…æ„Ÿç®±å‹å›¾")
print("   9. 09_pain_points_funnel.png - ç—›ç‚¹æ¼æ–—å›¾")
print("  10. 10_comprehensive_dashboard.png - ç»¼åˆä»ªè¡¨ç›˜")

print("\nğŸ“„ è¯´æ˜æ–‡æ¡£:")
print("   - å›¾è¡¨è¯´æ˜æ–‡æ¡£.md - æ¯å¼ å›¾çš„è¯¦ç»†è¯´æ˜å’Œä½¿ç”¨å»ºè®®")

print("\nâœ¨ æ‰€æœ‰å›¾è¡¨å‡ä¸ºé«˜æ¸…PNGæ ¼å¼ï¼ˆ300 DPIï¼‰ï¼Œé€‚åˆ:")
print("   - PPTå±•ç¤º")
print("   - æ‰“å°æµ·æŠ¥")
print("   - è®ºæ–‡æ’å›¾")
print("   - æ¯”èµ›ç­”è¾©")

print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
print("   1. æŸ¥çœ‹ å›¾è¡¨è¯´æ˜æ–‡æ¡£.md äº†è§£æ¯å¼ å›¾çš„ç”¨é€”")
print("   2. æ ¹æ®PPTéœ€æ±‚é€‰æ‹©åˆé€‚çš„å›¾è¡¨")
print("   3. é…åˆæ´å¯Ÿæ–‡å­—è®²å¥½æ•°æ®æ•…äº‹")
print("   4. å‡†å¤‡3åˆ†é’Ÿæ¼”ç¤ºè„šæœ¬")

print("\n" + "=" * 80)
print("ç¥ä½ æ¯”èµ›é¡ºåˆ©ï¼ğŸš€")
print("=" * 80)
